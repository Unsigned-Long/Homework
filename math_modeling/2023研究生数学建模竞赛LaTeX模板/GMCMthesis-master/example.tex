% !Mode:: "TeX:UTF-8"
%!TEX program  = xelatex
% 引入相关的包
\documentclass[bwprint]{gmcmthesis}
%\usepackage[hidelinks]{hyperref}
%\usepackage[table,xcdraw]{xcolor}
\usepackage{amsmath, listings, fontspec, geometry, graphicx, ctex, color, subfigure, amsfonts,amssymb}
\usepackage{multirow}
\usepackage[ruled]{algorithm2e}
\usepackage[framemethod=TikZ]{mdframed}
%\usepackage{subfloat}
\title{正态假设下基于自适应权因子分配的竞赛评审方案}
\baominghao{23104860059} %参赛队号
\schoolname{  武汉大学  }%学校名称
\membera{赵叶豪} %队员A
\memberb{陈烁龙} %队员B
\memberc{吴飞扬} %队员C

\newfontfamily\ubuntu{Ubuntu Mono}
\newfontfamily\consolas{Consolas}
% 代码块的风格设定
\lstset{
	language=C++,
	basicstyle=\footnotesize\ubuntu,
	keywordstyle=\textbf,
	stringstyle=\itshape,
	commentstyle=\itshape,
	numberstyle=\footnotesize\ubuntu,
	showstringspaces=false,
	numbers=left,
	numbersep=8pt,
	tabsize=2,
	frame=single,
	framerule=1pt,
	columns=fullflexible,
	breaklines,
	frame=shadowbox, 
	backgroundcolor=\color[rgb]{0.97,0.97,0.97}
}

\begin{document}
\newcommand\normf{}
%\newcommand\mlcomment[1]{}
 %生成标题
 \maketitle

 %填写摘要

\begin{abstract}
当今世界正经历百年未有之大变局，新一轮科技革命和产业变革深入发展。
习近平在二十大报告中强调，必须坚持科技是第一生产力、人才是第一资源、创新是第一动力，深入实施科教兴国战略、人才强国战略、创新驱动发展战略，开辟发展新领域新赛道，不断塑造发展新动能新优势。各行业创新型成果作品层出不穷、百花齐放，相应的学科竞赛也随之而起，为筛选高质量创新型成果提供了一个较为优良的平台，激励着创新型人才的持续性培养。

当前，针对大规模的创新型竞赛，一般采用两阶段的评审方法，通过标准分计算方法和极差剔除策略，保证参赛作品评分的公平性。但是，对于创新性作品评分的而言，评审专家的个人主观因素会极大地干扰所给出的作品评分，导致作品评分之间的可比性降低。特别是当参赛作品较多，评审专家较少时，此问题更加突出。而且，简单地依据多位评委评分的总和进行排序并不是创新类竞赛评审的可靠方案。基于上述给出的大规模创新型竞赛评审现状，探讨对应较为合理的评审方案，并探讨其公正性、公平性和科学性具有深远意义。

在本次研究中，我们从$(i)$作品分发、$(ii)$标准分计算和$(iii)$大极差分数调整三个方面出发，构建了一套针对大型创新型竞赛评审的方法。具体来说：
\begin{enumerate}
\item 针对问题一，我们通过构建无向图的方式描述各评审专家作品分发的关系，并为其构建了一个包含边数因子和分布因子的评价指标。基于此指标，可以求解最优的作品分发策略。在基于大样本服从正态分布的假设下，随机分发策略是最优的方案。

\item 针对问题二，我们从专家打分偏好对作品评分的影响这一方面出发，在样本水平分布服从正态分布的假设条件下，通过从专家评审作品的分数集合中计算得到对应的自适应加权因子，对各专家的评分进行加权调整，极大地减弱了专家个人因素对作品评分的影响。

\item 针对问题三，考虑到创新型作品评分的大极差特性，我们提出了基于极差的自适应挑选策略，并对符合阈值的争议作品进行基于标准分的反距离加权平均，得到作品的评分。

\item 在问题四中，我们基于前文所述的各阶段优化方案和策略，提出了一个针对大规模的创新型竞赛的完整评审方法。在正态分布假设下，通过随机分发策略、对不同专家构建自适应加权因子、对二阶段有争议作品使用基于极差的筛选及评分调整方法，极大地保证了创新型竞赛中作品的评审公平性和合理性。
\end{enumerate}

当然，当前所提出的最优分配策略和评分体系是在作品符合正态分布的假设前提下得到的，当作品不满足正态分布，或者存在其他关于作品或评审专家的先验信息时，需要研究可靠性更好的方法，如通过贝叶斯网络建模求解。这在未来的工作中可以进行相应的探索与研究。

\keywords{无向图网络\quad 最优分发算法\quad  自适应极差探测与筛选\quad  正态分布\quad 反距离加权平均 \quad 最小二乘算法}
\end{abstract}

\pagestyle{plain}

%目录 不推荐加
%\tableofcontents

\section{问题简介}

\subsection{问题背景}
\par
在信息技术高速发展，各学科、科研领域不断挑战、寻求突破的时代，如何打破信息壁垒，促进知识交叉与学术交流，同时凸显该领域最新、最优研究结果，实现成果筛选、成员激励、标杆树立等多方面目标，是各领域从业人员需要解决的难题，也是其促进自身发展的内在需求。而大规模创新类竞赛可以同时面向上述目标，充分达到竞争、合作、筛选、促学、激励等诸多目的。当前各类创新类学科竞赛已成为高校人才培养的重要环节,其目的与我国高等教育教学改革过程中培养具有创新精神和实践能力的高素质创新型人才的要求是不谋而合的。
无论在国内还是国际舞台上，大规模的创新类竞赛数量不断增多，其面向群体、领域以及内容、评价方式等都各不相同。然而当竞赛规模基数足够庞大，而进行评价的权威性专家众多且受限的情况下，各专家的评价标准、偏好等存在较大差异。由于大型比赛严谨求实、客观公正的评价要求，建立客观完善的评价机制，保证竞赛的公正性、公平性以及科学性是其需要考虑的关键问题之一。
\par
当前大型赛事赛事的评审方法模型依然在不断摸索与搭建，目前较为主流的简易方法也已经在题述中给出。方法(1)对不同的评委分数标准化归入某一区间，将不同评委的标准分加和，作为总分后排序，这种方法有效避免了不同评委的打分偏好差异，却无法兼顾评委的打分作品域大小差异的影响；方法(2)剔除最高分数与最低分数，将剩余评分相加后作为总分排序。这种方法可以防止极大或极小分数对总体分数带来的影响，但是在极差(题目附件一定义)较大的情况下剔除最大最小值可能并不能缩小极差，并且明显存在数据利用不充分问题；方法(3)对极差较大的组别组织专家协商调整，给出复议分后再进行总分相加排序，这种方法虽然能提升排名的合理性，但是普适性不足，并且工作量较大。在上述三个方案的基础上，题目又提出了两阶段评审的方案(4)，方案(4)使用两段评审方法，首先进行初选，对初选入围的组别进行第二阶段评审，再确定最终获奖名单。这种方法可以在不影响大赛获奖等级的情况下，解决评委专家数目受限的问题。
\par
目前，国内、国际学术界对于大规模竞赛的评价打分体系没有明确的统一标准，相关研究的数目较少，也留有较多空白区域亟待填补。
\par
在现有大赛数据和现有评审方案的基础上，本题要求参赛者分析试题分发的分配方案，分析评委的打分模式，对比并具体展现出几类评审方法的优点与缺点，以及讨论创新型大赛的评判标准与依据，最终构建出一个尽可能客观公正、明确易行的大规模创新类竞赛的评价体系，建立相应数学模型。该问题不仅可以为各大赛事提供最为完善的评分解决方案，同时也惠及众多比赛的参赛选手，确保每份努力都获得相应的回报。

\subsection{问题重述}
\par
基于该问题的研究背景，本题除提供题目及描述外，还以附录形式提供了极差的定义、标准分计算方法，以及某三份大赛评分的评分明细及作品排名，依托以上资料及数据解决以下问题：
\par
问题一：不同专家的评分作品集合有大小差别，不同专家的评分作品交集也存在大小差别。需要确定一种判定指标与相对最优的数学模型，每份作品需要5位专家打分，在3000份作品对125位专家的“交叉分发”方案中找到最具可比性且科学客观的分发方案。
\par
问题二：由于不同专家的评分作品集合交集大小不同，当前基于附件1标准分定义可能存在问题。本题要求（1）结合附件2提供的数据1分析每位专家/每份作品所打出/获得分数的分布特点；（2）结合分布特点探究标准分更加合理可靠的计算公式；（3）数据1的一等奖获奖作品认为具有最大可信度，结合此结果改进标准分计算模型。
\par
问题三：创新性作品没有标准答案，往往出现评分极差大的问题。对于大极差作品，结合评委复议分的赋分规律，依托模拟数据2.1和2.2，进行两阶段成绩及极差的变化规律分析，并评判两阶段评审和单阶段评审的优缺点，同时建立程序化模型处理大极差作品。
\par
问题四：构建创新类竞赛的完整评审模型，讨论对先行方案改进的具体建议。
\newpage
\section{问题分析}

\subsection{问题一分析}
\par
针对问题一，我们认为交叉分配的核心目标在于以下两点：
\par
（1）不同评审专家所评审的作品之间的可比性更强（即要求各作家的评审作品尽可能产生多的交叉）。
\par
（2）各专家评审作品的作品分布更加均匀且专家的工作量尽可能相同（即元素的交集尽可能数量相同）。
\par
在此构建模型，将其抽象为无向图的形式抽象表示评价目标。同时构建两个专家评审作品的交集的数学表示，并充分考虑上述两个影响因素，将其模型化表示为一个唯一的评价指标。我们以此指标为导向，设定并验证了所提出的最优随机分配策略和设定的滑动窗口分配策略、块分配策略两种不同的典型分配策略，在模型构建与策略验证后唯一确定出最终策略：最优随机策略。



\subsection{问题二分析}
\par
在问题二中，需要根据数据1详细分析各专家的打分偏好（即其所评作品集合的分布情况）以及各作品的专家评分的分布情况，最终优化标准分计算公式。
\par
我们认为，假设没有情绪因素，一个客观公正的专家在自己所面对的足够大作品集（根据数据1，每位专家均能分得100-120份作品）所打出的分数应该服从正态分布，而根据生活经验和各类大赛的实际经验，在大规模（即样本数够大）的情况下其作品的优劣质量也应该服从正态分布。因此构建相似性指标，确立相似性系数来考量某位专家其评审作品集合分布与正态分布的相似性；利用QQ图鉴别样本数据是否近似正态分布。构建QQ散点图的相关系数与自适应加权因子的关系，再将自适应相关因子引入标准分构建公式，比较各种引入方法的效果。
\par
随后探究各作品专家评分的分布情况，计算每个作品标准分的重心，使用IDW算法（反距离加权）加权平均计算新的标准分，对比具有权威性的一等奖复议结果，进一步优化标准分计算模型。
\par
结合上述两步自适应相关因子和反距离加权平均方法，最终获得改进后的标准分计算公式。

\subsection{问题三分析}
\par
问题三围绕“极差”展开，极差的定义已由附件给出。通过绘制频数分布直方图，探究各阶段的成绩和极差的整体分布。通过二阶段中进入复议环节和未进入复议环节作品的极差分布特征，建立基于极差的筛选模型。再根据作品标准分的极差特征，构建极差调整模型，以最大化的减小大极差和高水平作品(尤其是创新性竞赛中的作品)的矛盾性。

\subsection{问题四分析}
\par
基于上述三个问题中构建的随机分发模型、反距离加权平均分数模型、自适应极差调整模型，构建大型创新性竞赛的评审系统。

\section{模型假设与符号说明}

\subsection{模型假设}
基于已有的竞赛评分先验知识，我们给出的假设为：
\begin{enumerate}
	\item 在大型竞赛中，作品的水平服从同一个正态分布。同时每个评审专家分配到的待评审作品的水平也服从正态分布；
	\item 在数据一中，进入第二阶段并获得一等奖的作品的名次具有可信度，也即经多位专家协商一致的获奖论文具有较大的合理性；
	\item 当作品在评审阶段的分数出现大极差现象时，离群值的可信度更低，在群值的可信度更高；
\end{enumerate}

\subsection{符号说明}

\begin{tabular}{cc}
	\midrule[1pt]
	\makebox[0.4\textwidth][c]{符号} &  \makebox[0.5\textwidth][c]{意义} \\ \midrule[1pt]\midrule[1pt]
	$\mathcal{W}=\{\cdots,w_i,\cdots\}$    & 待评审作品集合，集合中的第$i$个作品 \\ \hline
	$\mathcal{E}=\{\cdots,e_j,\cdots\}$    & 评审专家集合，集合中的第$j$个评审专家 \\ \hline
	$\mathcal{W}(e_j)$    & 第$j$个评审专家分配到的作品集合 \\ \hline
	$\mathcal{E}(w_i)$    & 第$i$个作品被分配到的专家集合 \\ \hline
	$s_{src}$    & 原始分 \\ \hline
	$s_{std}$    & 标准分 \\ \hline
	$s_{rew}$    & 复议分，只出现在二审阶段 \\ \hline
	$s_{rng}$    & 分数极差\\ \hline
	$\mathcal{S}^i_{src,1}=\{s^{i,k}_{src,1}\;\vert\; k=1,2,3,4,5\}$    & 第$i$个作品在一审阶段的原始分集合  \\ \hline
	$\mathcal{S}^i_{std,1}=\{s^{i,k}_{std,1}\;\vert\; k=1,2,3,4,5\}$    & 第$i$个作品在一审阶段的标准分集合  \\ \hline
	$\mathcal{S}^i_{src,2}=\{s^{i,k}_{src,2}\;\vert\; k=1,2,3\}$    & 第$i$个作品在二审阶段的原始分集合  \\ \midrule[1pt]
\end{tabular}

\begin{tabular}{cc}
	\midrule[1pt]
	\makebox[0.4\textwidth][c]{符号} &  \makebox[0.5\textwidth][c]{意义} \\ \midrule[1pt]\midrule[1pt]
		$\mathcal{S}^i_{std,2}=\{s^{i,k}_{std,2}\;\vert\; k=1,2,3\}$    & 第$i$个作品在二审阶段的标准分集合  \\ \hline
	$\mathcal{S}^i_{rew,2}=\{s^{i,k}_{rew,2}\;\vert\; k=1,2,3\}$    & 第$i$个作品在二审阶段的复议分集合  \\ \hline
	$\mathcal{S}$    & 最终的作品评分集合，决定了作品的排名  \\ \hline
	$n(\mathcal{A})$    & 集合$\mathcal{A}$内元素的个数  \\ \hline
	$\mu(\mathcal{A})$    & 集合$\mathcal{A}$内元素的均值(向量)  \\ \hline
	$\sigma(\mathcal{A})$    & 集合$\mathcal{A}$内元素的标准差(向量) \\ \hline
	$\sigma(\mathcal{A},\mathcal{B})$    & 集合$\mathcal{A}$和$\mathcal{B}$之间的协方差(矩阵) \\ \hline
	$\rho(\mathcal{A},\mathcal{B})$    & 集合$\mathcal{A}$和$\mathcal{B}$之间的相关系数 \\ \hline
	$\min\{\mathcal{A}\}$    & 集合$\mathcal{A}$内的最小元素 \\ \hline
	$\max\{\mathcal{A}\}$    & 集合$\mathcal{A}$内的最大元素 \\ \hline
	$\mathcal{A}\cap\mathcal{B}$    & 集合$\mathcal{A}$和$\mathcal{B}$的交集 \\ \hline
	$\mathcal{A}\cup\mathcal{B}$    & 集合$\mathcal{A}$和$\mathcal{B}$的并集 \\ \midrule[1pt]
\end{tabular}
\newpage
\section{模型建立与结果分析：问题一 }
\subsection{交叉分配方案}

	\par
	在大型创新性竞赛的评审流程中，为了增加不同评审专家所给成绩之间的可比性，需要让不同专家评审的作品集合之间有交集。但若有的专家组合之间的作品交集大了，则必然存在交集小的评审专家组合，导致可比性变弱。对此，为了解决交叉分配问题，增加作品评分的可信度，需要提升不同评审专家作品集合之间的可比性，同时尽可能保证各专家的作品集合能够大小相似，即确保其工作量基本一致。因此我们基于无向图模型，定义一个评价无向图优劣的指标，通过最大化该指标，得到最优的作品分发策略。
	
	设专家集合为$\mathcal{E}$，由题意知，有$n(\mathcal{E})=125$。作品集合为$\mathcal{W}$，且有$n(\mathcal{W})=3000$。设第$i$个专家评审的作品集合为$\mathcal{W}(e_i)$，有$n(\mathcal{W}(e_i))\in[0,1,\cdots,3000)$，第$j$个作品的评审专家集合为$\mathcal{E}(w_j)$，有$n(\mathcal{E}(w_j))=5$。
	
	另外，设$\mathcal{G}$为两两专家对的集合，对于$\mathcal{G}$内的每个元素(每对专家组合)，根据两专家之间是否存在共同的评审作品，对其分类到两个集合：
	\begin{equation}
		\mathcal{G}\mapsto\begin{cases}
			\mathcal{G}_1&n\left(\mathcal{W}(e_i)\cap\mathcal{W}(e_j) \right)=0\\
			\mathcal{G}_2&n\left(\mathcal{W}(e_i)\cap\mathcal{W}(e_j) \right)> 0\\
		\end{cases}
	\end{equation}
	其中$\mathcal{G}_1$表示两评审专家不存在相同的评审作品，$\mathcal{G}_2$表示两评审专家存在相同的评审作品。基于此，易得两个集合的元素个数为：
	\begin{equation}
		n(\mathcal{G}_1)=\sum_{i=1}^{n(\mathcal{E})}\sum_{j=i+1}^{n(\mathcal{E})}
		\delta(n\left(\mathcal{W}(e_i)\cap\mathcal{W}(e_j) \right)-0)
	\end{equation}
	\begin{equation}
		n(\mathcal{G}_2)=
		n(\mathcal{G})-n(\mathcal{G}_1)=
		C_{n(\mathcal{E})}^{2}-\sum_{i=0}^{n(\mathcal{E})-1}\sum_{j=i+1}^{n(\mathcal{E})-1}
		\delta(n\left(\mathcal{W}(e_i)\cap\mathcal{W}(e_j) \right)-0)
	\end{equation}
	其中$\delta(x-x_0)$为狄拉克$\delta$函数\cite{闵琦2004delta}：
	\begin{equation}
		\delta(x-x_0)=\begin{cases}
			1&x=x_0\\0&x\ne x_0
		\end{cases}
	\end{equation}
	\par
	
	接着将各作家所评价的作品集合抽象为顶点，将两位作家所评价的作品集合交集抽象为边，以此构建一个无向图\cite{bloom1977applications}，如图\ref{fig:所构造指标的无向图示意图}所示。
	\begin{figure}[t]
		\centering
		\includegraphics[width=\linewidth]{/home/csl/Documents/fig/math_modelingpargh.pdf}
		\caption{\normf 所构造指标的无向图示意图}
		\label{fig:所构造指标的无向图示意图}
	\end{figure}
	该无向图中共有$n(\mathcal{E})$个节点，一个节点表示一个专家所评审的作品集合。若两个专家所评审的作品集合的交集非空，则两个对应节点用边连通。边的粗细(权重)与交集中元素个数成正比。
	
	为了增加不同专家评审的作品集合之间的交集，应使得使得该无向图在保证边的数目足够多(交集数目尽可能多)的情况下，同时边的粗细均匀(避免不同交集元素数目之间差异过大)。
	
	为此，我们在同时考虑让边数目尽可能多和边尽可能粗的条件下，构建了如下的评价指标，用来衡量无向图的优劣：
	
	\begin{equation}
	\label{equ:专家加权因子计算}
	\rho=\frac{
		\begin{aligned}
			n(\mathcal{G}_2)
		\end{aligned}
	}{
		\begin{aligned}
			\left( 	n(\mathcal{G}_1)+n(\mathcal{G}_2)\right) \cdot(1+\sigma)
		\end{aligned}
	}
\end{equation}
其中的标准差计算如下所示：
\begin{equation}
	\sigma^2=	\frac{
		\begin{aligned}
			\sum_{i=1}^{n(\mathcal{G}_2)}
			\left( 
			n\left(\mathcal{G}_2^i \right) -\bar{n}{(\mathcal{G}_2) }
			\right) ^2
		\end{aligned}
	}{
		\begin{aligned}
			n(\mathcal{G}_2)-1
		\end{aligned}
	}
	\qquad
	\bar{n}{(\mathcal{G}_2)}=\frac{1}{n(\mathcal{G}_2)}\cdot\sum_{i=1}^{n(\mathcal{G}_2)}n(\mathcal{G}_2^i)
\end{equation}
当无向图衡量指标$\rho$越大，表明无向图的网结构越优，也即作品分发方案越好。事实上，公式(\ref{equ:专家加权因子计算})由两部分因子构成：
\begin{enumerate}
	\item 边数因子$f_1$：在无向图节点数目一定$n(\mathcal{E})$的情况下，当：
	\begin{equation}
		f_1=\frac{n(\mathcal{G}_2)}{n(\mathcal{G}_1)+n(\mathcal{G}_2)}
	\end{equation}
	因子的值越大，边数越多，即交集数目越多。
	
	\item 分布因子$f_2$：在无向图边数一定的情况下，当
	\begin{equation}
		f_2=\frac{1}{1+\sigma}
	\end{equation}
	因子的值越大，即$\sigma$越小时，表示边的粗细越均匀，也即不同交集元素数目之间差异较小。为了避免$f_1$过小但$\sigma$接近0导致评价指标异常的情况发生(见下面所选的块分配方案)，在$\sigma$上补偿了一个单位量。
\end{enumerate}

在完全没有先验信息，如作品质量、专家评分偏好等未知的情况下，如下的随机分配策略是指标$\rho$下的最优分配策略：
\begin{algorithm}[h]
	\caption{\normf{最优随机策略}}
	\LinesNumbered 
	\KwIn{\normf{作品集合$\mathcal{W}$，评审专家集合$\mathcal{E}$，每份作品需被评审的次数$n$(在此案例中为5)。}}
	\KwOut{\normf{每位专家评审的作品集合$\mathcal{W}(e_j)$，或者每个作品被评审的专家集合$\mathcal{E}(w_i)$。}}
	\ForEach{$w_i\in\mathcal{W}$}{
		\normf{对当前作品随机选取的评审专家集合} $\mathcal{E}(w_i)=\{\}$
		
		\For{\normf{$n$}}{
			\normf{随机选取一个专家$e_j\in\mathcal{E}$}，满足$e_j\not\in\mathcal{E}(w_i)$	
			
			$e_j\rightarrow\mathcal{E}_s$
		}
		\normf{包含$n$个专家的集合$\mathcal{E}_s$即为当前作品$w_i$随机分配到的评审专家集合。}
	}
\end{algorithm}

为此，我们考虑了三种不同的典型分配策略：
	\begin{enumerate}
		\item 所提出的随机分配策略：由于没有作品和评审专家的先验知识，采用随机发放的方式。对于每个作品，随机选取一定数目的专家进行评审。
		\item 滑动窗口分配策略：
		首先将评审专家进行有序排列成环，每次将作品分配给窗口内相邻的$5$个评审专家。在对下一个作品进行分配时，将窗口向右滑动一步，窗口内靠前的专家不再参与评审，并从后方递补一位专家参与该作品的评审，直至所有作品被分配完毕。具体的执行过程如图\ref{fig:滑动窗口分配策略示意图}所示。
		%		\mlcomment{
		\begin{figure}[h]
			\centering
			\includegraphics[width=\linewidth]{/home/csl/Documents/fig/win_select.pdf}
			\caption{\normf 滑动窗口分配策略示意图}
			\label{fig:滑动窗口分配策略示意图}
		\end{figure}
	
		\item 块分配策略：将125名专家平均分组，每5个专家分为一个小组，共25组。再将3000份作品平均分组，每120个作品作为一组，共25组。为专家组和作品组分别按顺序编号，在进行评审时，对应编号的专家组评审对应作品。具体的执行过程如图\ref{fig:块分配策略示意图}所示。
%		\mlcomment{
	\begin{figure}[h]
			\centering
			\includegraphics[width=\linewidth]{/home/csl/Documents/fig/block_select.pdf}
			\caption{\normf 块分配策略示意图}
			\label{fig:块分配策略示意图}
		\end{figure}
	\end{enumerate}

表\ref{tab:三种交叉分配策略指标的计算值}列出了三种分配模型的边数因子$f_1$、分布因子$f_2$以及最终因子$\rho$的相应指标（其中由于最优随机分配策略的随机性，此处所列指标为3000次模拟的指标平均值）。
\begin{table}[h]
	\centering
	\caption{三种交叉分配策略指标的计算值}
	\begin{tabular}{cccc}
		\midrule[1pt]
		& 最优随机分配策略 & 滑动窗口分配策略 & 块分配策略 \\ \midrule[1pt]\midrule[1pt]
		$f_1$ & 0.763    & 0.065    & 0.032 \\
		$f_2$ & 0.489    & 0.050    & 1.000    \\
		$\rho$  & 0.373      & 0.003    & 0.032 \\ \midrule[1pt]
	\end{tabular}
	\label{tab:三种交叉分配策略指标的计算值}
\end{table}
由上表可得，显然最优随机分配的边数因子$f_1$为0.763最大，分布因子$f_2$为0.489，在0至1区间内最接近中间值，最终求得的评价因子指标$\rho$为0.373，远高于滑动窗口分配策略和块分配策略。因此在本指标所构建的评价体系下，我们提出的最优随机分配策略表现最为出众。

为了探究最优随机分配策略的稳定性(随机性)，我们进行了3000次最优随机分配的蒙特卡洛模拟分发，如图\ref{fig:最优随机分配的蒙特卡洛模拟}所示。
	\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{/home/csl/Documents/fig/三个因子分布.pdf}
	\caption{\normf 最优随机分配的蒙特卡洛模拟}
	\label{fig:最优随机分配的蒙特卡洛模拟}
\end{figure}
上图从左至右分别为边数因子$f_1$、分布因子$f_2$和最终指标$\rho$的频数分布直方图与概率密度分布图\cite{barfoot2017state}，横坐标表示对应数值，纵坐标表示频数。两种因子及最终指标均匀分布在平均值附近，呈现较为稳定的分布趋势；并且其所得数值绝大多数都要优于滑动窗口分配策略和块分配策略。

因此，我们探究构建的最优随机分配策略被认为是较为为合理的作品交叉分配策略，尤其是在没有任何作品和评审专家相关的先验知识的前提下。最优随机分配策略在保证了各专家评审作品集合的可比性的同时保证了专家之间的工作量均衡，同时其中所蕴含的有限随机思想也进一步保证了分配的公平性、合理性。

\newpage

\section{模型建立与结果分析：问题二 }

\subsection{\normf{评分模型}}
%\begin{enumerate}
	\subsubsection{\normf{自适应加权因子}}
	\par
	针对问题二，现有的标准分评价策略为确定的公式所计算出的标准分数，该分数的主要作用是把不同打分偏好的专家所评审的原始分数归算至统一区间内，从而方便后续的统计和排名。但其只能在宏观层面把握整体的打分区间，无法细致的考虑到每位专家的打分的均衡性和客观性，因此在最终的归算中依旧存在缺陷。
	\par
	实际上，专家根据自身的经历、研究领域、主观喜好等方面的影响常常存在打分偏好，导致分数不够客观出现偏差。我们考虑到一个完全不带情绪倾向，客观的理性专家，在其打分作品集合足够大的情况下，所给出的分数应当是完全符合正态分布\cite{johnson1987normal}的；在此我们将专家所给出分数所呈现的分布情况与正态分布之间的关系作为我们的研究目的之一。
	
	根据评审专家对所分配到的作品集合的打分情况(符合正态分布的程度)，在现有的标准分计算模型\cite{孙荣恒2000概率论和数理统计}的基础上，考虑构建一个额外的自适应加权因子，从而拓展标准分打分公式的适应性与合理性。我们的理由在于，标准分模型考虑评审专家打分的整体偏差(整体过高或过低)，可以在保证被评审作品分数相对高低不变的情况下，去除掉不同专家的打分偏差。但是由于不同作品集合的学术水平分布不一定相同，因此不同集合中作品的可比性不一定相同。每个作品最终在整体中的排位情况由多个专家的给分共同决定，即通过作品在多个不同子集中的排名情况去反映其在全集中的排名情况。通常，在一个比赛中，当参赛队伍数量较大时，我们可以假定参赛作品的水平是满足正态分布的。因此，若某个专家评审的作品集的分布与正态分布相似度低，则该专家的打分具有较低的参考意义，如图\ref{fig:评委打分权低示意图}所示；若某个专家评审的作品集的分布与正态分布相似度高，则该专家的打分具有较高的参考意义，如图\ref{fig:评委打分权高示意图}所示。
	
	
	\begin{figure}[h]
		\centering
		\includegraphics[width=\linewidth]{/home/csl/Documents/fig/评委打分_权低.pdf}
		\caption{\normf 评委打分权低示意图}
		\label{fig:评委打分权低示意图}
	\end{figure}
	\begin{figure}[h]
		\centering
		\includegraphics[width=\linewidth]{/home/csl/Documents/fig/评委打分_权高.pdf}
		\caption{\normf 评委打分权高示意图}
		\label{fig:评委打分权高示意图}
	\end{figure}
	
	基于此，对于第$i$个评审专家的作品集合$\mathcal{W}(e_i)$，验证其分数分布的正态特性，以此作为专家加权的依据。为此，针对其原始分数集合，我们通过正态QQ图\cite{das2008qq}(Quantile-Quantile plot,QQ图)直线拟合\cite{weisstein2002least}时的相关系数相关系数的平方$\rho^2\in[0,1]$，将其作为自适应加权因子。具体来说，针对第$k$个样本，对分数小于$y_k$的样本概率进行累积，得到其累积概率为：
	\begin{equation}
		F_k=\sum_{s=0}^{k}p_s=\int_{y=-\infty}^{x_k}\frac{1}{\sqrt{2\pi}}\exp\left( -\frac{y^2}{2}\right) 
	\end{equation}
	其在QQ图上的对应点为$(x_k,y_k)^\top$。而后进行线性最小二乘法，对点集进行直线$y=ax+b$拟合：
	\begin{equation}
	\begin{pmatrix}
	v_1\\\cdots \\v_n
	\end{pmatrix}
	=\begin{pmatrix}
	x_1&1\\\cdots&\cdots\\x_n&1
	\end{pmatrix}
	\begin{pmatrix}
	a\\b
	\end{pmatrix}-\begin{pmatrix}
	y_1\\\cdots \\y_n
	\end{pmatrix}
	\end{equation}
	求解得到直线的待定参数$a$和$b$。
	QQ图鉴可以鉴别样本数据是否近似于正态分布。当QQ图上的点近似地在一条直线附近，说明是正态分布。为了度量样本分布与正态分布的相似性，计算QQ图上散点的相关系数\cite{asuero2006correlation}:
	\begin{equation}
		\rho=\frac{\sigma_{xy}}{\sigma_x\cdot\sigma_y}\in[-1,1]
	\end{equation}
	得到最终的自适应加权因子$w=\rho^2$。
	而后在原始的标准分计算公式的基础上乘以该自适应加权因子，得到新的标准分。
	
	\subsubsection{\normf{标准分优化：因子引入}}
	\par
	
	自适应加权因子$w$可以良好且直观的反映专家的评审分数可信度，以此各专家所评审的分数也能差异化的获得更适宜的标准调整。自适应加权因子的作用策略有两种方式：
	\begin{enumerate}
		\item 全局自适应因子：将整个自适应因子作用到原来的整个标准分计算模型上，如下式所示：
		\begin{equation}
		s_2=w\times\left( 50+10\times\frac{y-\bar{y}}{\sigma_y}\right) 
		\end{equation}
		由于全局自适应因子作用到整个标准分计算公式上，导致标准分的均值发生了偏移：自适应因子大的专家评分均值更大，自适应因子小的专家评分均值更小。
		
		\item 局部自适应因子：将整个自适应因子作用到原来标准分计算模型的归化项(即非常数项)上，如下式所示：
			\begin{equation}
		s_2=50+w\times10\times\frac{y-\bar{y}}{\sigma_y}
		\end{equation}
		在原先标准分计算模型里，乘法因子10决定了分数分布的区间长度，即分数最高和最低作品之间的差值。显然，对于不同的评审专家而言，这个区间应该不同：$(i)$ 对于自适应加权因子大的评审专家(即打分满足正态分布)，由于其打分较为合理，能够较大的差异化好坏作品之间的分数差距；$(ii)$对于自适应加权因子小的评审专家(即打分不满足正态分布)，其打分可能存在其他干扰因素，所以打成绩的可信度不高，所以缩小不同作品之间的分数差距(即分数分布区间较小)，能够避免误判的情况发生，因为此时作品的最终成绩受该评审专家的影响较小。经过我们进行的多次测试，发现使用局部自适应因子是更好的选择。
	\end{enumerate}

	\subsubsection{\normf{模型优化：IDW算法}}
	在专家对作品的打分过程中，可能出现其中一个专家的打分与另外几个专家的打分有明显差距。此时，该作品的真实得分通常应当与另外几个专家的打分更为接近。
	因此为了处理极差较大问题，我们提出了分数的反距离加权(Inverse Distance Weighted，IDW)平均算法。在第二阶段中，我们首先对每个作品的分数极差进行计算，进而对所有的极差计算平均值与标准差。在计算作品的第二阶段得分时，若作品的极差大于极差平均值与一倍标准差之和，则认为出现了专家对作品打分异常的情况，此时计算标准分的反距离加权平均值，并将其乘以3作为作品第二阶段得分。
	
		对于第$i$个作品$w_i$，其一阶段标准分集合为$\mathcal{S}^i_{std,1}=\{s^{i,1}_{std,1},s^{i,2}_{std,1},s^{i,3}_{std,1},s^{i,4}_{std,1},s^{i,5}_{std,1}\}$，其第一阶段的评分为：
	\begin{equation}
		s^i_1=\mu\left( \mathcal{S}^i_{std,1}\right) 
	\end{equation}
	设$w_i$为参与了第二阶段评审的第$i$个作品，其标准分集合为$\mathcal{S}^i_{std,2}=\{s^{i,1}_{std,2},s^{i,2}_{std,2},s^{i,3}_{std,2}\}$，则计算其极差：
	\begin{equation}
		s_{rng,2}^i=\max\{\mathcal{S}^i_{std,2}\}-\min\{\mathcal{S}^i_{std,2}\}
	\end{equation}
	对于极差集合$\mathcal{S}_{rng,2}=\{\cdots,s^{i}_{rng,2},\cdots\}$，其均值为$\mu\left( \mathcal{S}_{rng,2}\right) $，方差为$\sigma\left(\mathcal{S}_{rng,2} \right) $，则对于：
	\begin{equation}
		s^i_{rng,2}>\mu\left( \mathcal{S}_{rng,2}\right)+\sigma\left(\mathcal{S}_{rng,2} \right)
	\end{equation}
	的作品，其第二阶段的评分采用如下的反距离加权平均：
	\begin{equation}
		s^i_2=\frac{3}{\begin{aligned}
				\sum_{j=1}^{
					3\times
				}\left( s^{i,j}_{std,2}-\mu\left(\mathcal{S}^i_{std,2} \right)\right) 
		\end{aligned}}
		\cdot\sum_{j=1}^{3}\frac{s^{i,j}_{std,2}}{\left( s^{i,j}_{std,2}-\mu\left(\mathcal{S}^{i}_{std,2} \right) \right) ^2} 
	\end{equation}
%	\end{enumerate}
	最终，第$i$个作品$w_i$的得分为两次评审阶段的分数之和：
	\begin{equation}
	s^i=s^i_1+s^i_2
	\end{equation}
	算法\ref{alg:作品评分方法}给出了具体的执行流程。
\newpage
\begin{algorithm}[h]
	\caption{\normf{作品评分方法}}
	\label{alg:作品评分方法}
	\LinesNumbered 
	\KwIn{\normf{作品集合$\mathcal{W}=\{\cdots,w_k,\cdots\}$，每个作品(比如$w_k$)一阶段评审专家集合$\mathcal{E}_1(w_k)$($n(\mathcal{E}_1(w_k))=5$)和二阶段的评审专家集合$\mathcal{E}_2(w_k)$($n(\mathcal{E}_2(w_k))=3$，如果作品没进入二阶段评审，则$n(\mathcal{E}_2(w_k))=0$)，评审专家集合包含了评审专家的编号和对应的原始评分。}}
\KwOut{\normf{每个作品的最终成绩集合$\mathcal{S}=\{\cdots,s^k,\cdots\}$。}}

\normf{构建一阶段的专家集合$\mathcal{E}_1$和二阶段的专家集合$\mathcal{E}_2$。每个集合里的元素为一个专家，其持有所审评作品集合。}

\normf{对于$\mathcal{E}_1$和$\mathcal{E}_2$中的每个专家，根据其所评作品集合的分数分布，计算正态分布相关系数，将$w=\rho^2$作为该评审专家打分时的自适应加权因子。}
\ForEach{$w_i\in\mathcal{W}$}{
	计算其一阶段的分数$s_1^i$	
}
分数排名靠前一定百分比的作品进入二阶段评审

在二阶段评审中
\ForEach{$w_i\in\mathcal{W}$}{
	计算该作品的评分极差$s_{rng,2}^i$。
	
	$s_{rng,2}^i\mapsto\mathcal{S}_{rng,2}$。
}
求$\mu(\mathcal{S}_{rng,2})$和$\sigma(\mathcal{S}_{rng,2})$。
\ForEach{$w_i\in\mathcal{W}$}{
	\If{$s^i_{rng}(2)>\mu(\mathcal{S}_{rng,2}+\sigma(\mathcal{S}_{rng,2})$}{对$\mathcal{S}^i_{std,2}$进行反距离加权平均，而后乘以$3$，得到$s_2^i$。}
	\If{$s^k_{rng}(2)\le\mu(\mathcal{S}_{rng,2}+\sigma(\mathcal{S}_{rng,2})$}{对$\mathcal{S}^i_{std,2}$中的元素进行累加，得到$s_2^i$。}
	计算进入二阶段的作品的总分。
	
	分数集合$\mathcal{S}$。
	\ForEach{$w_i\in\mathcal{W}$}{
		$s^i_1+s^i_2\mapsto s^i$	
		
		$s^i\mapsto\mathcal{S}$
	}
	对作品进行排序得到最终的排名。
	}
\end{algorithm}


\subsection{\normf{模型评价：序列相似性}}
\par
问题二认为附录1中的一等奖获得排名经过专家给出复议分并商议决定，作为权威性结果，具有一定的参考价值。为方便评估所构建模型的优化效果，对比分析各模型的优缺点，我们有两种方式来衡量离散序列的相似性：相关系数和曼哈顿距离的倒数。
设有两个排名序列$\mathcal{O}_1$和$\mathcal{O}_2$，且有$n(\mathcal{O}_1)=n(\mathcal{O}_2)$。这两个序列的元素相同，但是排列顺序不同，即不同的排名结果。则：
\begin{enumerate}
	\item 基于曼哈顿距离的序列相似性定义为：
	\begin{equation}
	s=\frac{1}{
		\begin{aligned}
		1+\sum_{i=0}^{n(\mathcal{O}_1)-1}\vert\mathcal{O}_1^i-\mathcal{O}_2^i\vert
		\end{aligned}
	}
	\end{equation}
	当两个序列完全一致时，$s=1$。
	
	\item 基于相关系数的序列相似性定义为：
	\begin{equation}
	R\left(\mathcal{O}_1,\mathcal{O}_2 \right)=\frac{cov\left(\mathcal{O}_1,\mathcal{O}_2 \right) }{
		\sigma\left(\mathcal{O}_1\right) \cdot\sigma\left(\mathcal{O}_2 \right) 	
	}
	\end{equation}
\end{enumerate}

	在此次评价中，我们主要使用了基于相关系数的序列相似性判断方法。
	下图\ref{fig:不同评分策略下的标准分分布示意图}中四幅图像分布表示（左上）原标准分与权威结果相似性、（左下）全局自适应因子标准分+反距离加权结果与权威结果相似性、（右上）局部自适应因子标准分+反距离加权结果与权威结果相似性、（右下）原标准分+反距离加权结果与权威结果相似性。
  图中$R^2$表示相关系数的平方，排名越相似散点应越接近坐标轴对角线。
\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{/home/csl/Documents/fig/不同评分策略.pdf}
	\caption{\normf 不同评分策略下的标准分分布示意图}
	\label{fig:不同评分策略下的标准分分布示意图}
\end{figure}

可以看到，局部自适应因子标准分计算策略加上反距离加权算法所得的散点贴近坐标轴对角线更更加紧密，并且相关系数$R^2$也更接近1。因此我们新构建算法模型是真实有效且可靠的，为今后各类大规模创新型赛事提供了崭新的标准分计算方案和模型优化方案。

\newpage
\section{模型建立与结果分析：问题三 }
\subsection{\normf{极差模型}}
\par
	我们首先对模拟数据2.2中进入第二阶段的作品在两个阶段的平均标准成绩分布进行了统计，并绘制了如下的频数分布直方图和QQ图。从中我们可以发现，平均成绩均是满足正态分布的。并且第一阶段的平均成绩均值明显高于第二阶段。这是因为进入第二阶段评审的作品，在第一阶段中均处于整体偏上的水准。同时进入二审作品的分数分布直方图的峰值出现在50附近，这与标准分计算公式相一致。

接着我们统计了进入第二阶段的作品在两个阶段的极差分布，同样满足正态分布规律。并且从图中可以看出，相比第二阶段，第一阶段的极差更为集中。相比于第一阶段，第二阶段大极差出现的频率更大，这说明进入第二阶段的作品整体是更具有创新性的。
\begin{figure}[h]
	\centering
	\includegraphics[width=0.85\linewidth]{/home/csl/Documents/fig/两阶段平均分分布.pdf}
	\caption{\normf 两阶段平均分分布示意图}
	\label{fig:两阶段平均分分布示意图}
\end{figure}


\begin{figure}[h]
	\centering
	\includegraphics[width=0.85\linewidth]{/home/csl/Documents/fig/两阶段极差分布.pdf}
	\caption{\normf 两阶段极差分布示意图}
	\label{fig:两阶段极差分布示意图}
\end{figure}

为了进一步探究某个作品的分数调整与专家评分之间的关系，我们将进入第二阶段评审的作品分为了三类：未复议作品$\mathcal{W}_{nr}$(no review scores)、复议后分数调高作品$\mathcal{W}_{hr}$(higher review scores)、复议后分数调低作品$\mathcal{W}_{lr}$(lower review scores)。将三类作品的第二阶段打分结果构成集合$\mathcal{S}_{nr}=\{\mathcal{S}^i_{std,2}\;\vert\; i\gets w_i\in\mathcal{W}_{nr}\}$，$\mathcal{S}_{hr}=\{\mathcal{S}^i_{std,2}\;\vert\; i\gets w_i\in\mathcal{W}_{hr}\}$，$\mathcal{S}_{lr}=\{\mathcal{S}^i_{std,2}\;\vert\; i\gets w_i\in\mathcal{W}_{lr}\}$。将三个集合中的分数向量在三维空间中进行表示。

\begin{figure}[h]
	\centering
	\includegraphics[width=0.48\linewidth]{/home/csl/Documents/fig/复议分调整3.pdf}
	\includegraphics[width=0.48\linewidth]{/home/csl/Documents/fig/复议分调整2.pdf}
	\includegraphics[width=0.48\linewidth]{/home/csl/Documents/fig/复议分调整1.pdf}
	\includegraphics[width=0.48\linewidth]{/home/csl/Documents/fig/复议分调整4.pdf}
	\caption{\normf 分数向量三维空间示意图}
	\label{fig:分数向量三维空间示意图}
\end{figure}
图\ref{fig:分数向量三维空间示意图}中绿、蓝、红三色的点分别表示未复议、复议后分数调低、复议后分数调高的作品。黑色虚线是100$\times$100$\times$100立方体空间中的一条对角线，即二阶段三次评分相同$s^{(\cdot)}_{2,1}=s^{(\cdot)}_{2,2}=s^{(\cdot)}_{2,3}$。图中绿色的点，即未复议作品均聚集在离黑色虚线较近的区域内。这是因为离黑色虚线越近，说明三个专家的评分越接近，极差越小，作品的评分越没有争议，因此不需要进行复议。我们可以根据这个特点来建立复议作品筛选模型。

		\begin{figure}[t]
	\centering
\subfigure[\normf{二阶段作品极差和复议关系示意图}]{
	\centering
	\includegraphics[width=0.45\linewidth]{/home/csl/Documents/fig/二阶段作品极差和复议关系.pdf}
	\label{fig:二阶段作品极差和复议关系示意图}
}
\subfigure[\normf{标准正态分布上分位数示意图}]{
	\centering
		\includegraphics[width=0.48\linewidth]{/home/csl/Documents/fig/正态分布分位数.pdf}
		
		\label{fig:标准正态分布上分位数示意图}
}
	\caption{二阶段作品极差和复议关系示意图和标准正态分布上分位数示意图}
\end{figure}
为了探究作品极差大小与其是否需要复议之间的关系，我们对进入二阶段评审的作品绘制了作品极差和复议关系图。图\ref{fig:二阶段作品极差和复议关系示意图}中绿色和蓝色的点分别代表未复议和复议的作品。从图中可以看到，这两类作品分别集中在图的上、下两部分。对进入二阶段评审作品的极差进行统计，其均值$\mu=10.75$，方差$\sigma=5.71$。未复议和复议的作品占比分别为$77.2\%$和$22.8\%$。在标准正态分布中(见图\ref{fig:标准正态分布上分位数示意图})，设$\alpha$为上分位数，则令：
\begin{equation}
	P(Z\le \alpha)=\Phi(\alpha)=\int_{-\infty}^{\alpha}\frac{1}{\sqrt{2\pi}}\exp{\left( -\frac{x^2}{2}\right) }dw=77.2\%
\end{equation}
\par

查表得到$\alpha\approx 0.745$。所以需要进行复议的作品的极差阈值为$\mu+\alpha\times\sigma$。
对单次评审和第一第二两次评审进行分析。将作品的一审排名作为横轴，作品的二审(即综合两次评审)排名作为纵轴，绘制得到图\ref{fig:一审排名和二审排名分布(左)，一审和二审极差分布(右)}左图。图上距离对角线$y=x$距离越远的点颜色越深，表示该作品的一二审排名偏差越大。并且我们可以看到所有的点并没有都紧密地分布在对角线周围，这说明对于很多作品，其一审排名与二审排名之间的相关性并不高。按照同样的方式绘制得到图\ref{fig:一审排名和二审排名分布(左)，一审和二审极差分布(右)}右图中一审二审的极差分布图，同样两者之间并无太强的相关性。这说明第二阶段的评审相对于第一阶段的评审是较为独立的，因此通过第二阶段评审可以增加对作品的独立打分次数，从而使得最终得分更能反映其真实水平。

\begin{figure}[h]
	\centering
	\includegraphics[width=0.48\linewidth]{/home/csl/Documents/fig/一审排名和二审排名分布.pdf}
	\includegraphics[width=0.48\linewidth]{/home/csl/Documents/fig/两阶段极差相关图.pdf}
	\caption{\normf 一审排名和二审排名分布(左)，一审和二审极差分布(右)} 
	\label{fig:一审排名和二审排名分布(左)，一审和二审极差分布(右)}
\end{figure}

图\ref{fig:调整前后大极差作品一二审排名分布示意图}为调整前后大极差作品一、二审排名分布示意图，对于由以上极差筛选策略筛选得到的极差较大作品，在去除一个最高分和一个最低分(即两个极差最大分数)之后计算其一审平均分数。分别对极差处理前后，极差较大作品的一二审排名相关性进行比较(见图\ref{fig:调整前后大极差作品一二审排名分布示意图})，可以发现，相关性由0.538提升到了0.571。说明我们的极差处理策略，能够在一定程度上使得作品的一审排名与二审排名更为接近。

\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{/home/csl/Documents/fig/调整前后大极差作品一二审排名分布.pdf}
	\caption{\normf 调整前后大极差作品一二审排名分布示意图}
	\label{fig:调整前后大极差作品一二审排名分布示意图}
\end{figure}

\newpage
\section{模型建立与结果分析：问题四 }
\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{/home/csl/Documents/fig/评分算法.pdf}
	\caption{\normf 评分算法示意图}
	\label{fig:评分算法示意图}
\end{figure}

 针对大规模创新型竞赛，考虑到其具有的交叉性、随机性和复杂性，在有限专家评审的条件下，为了保证作品评审的客观性和公平性，我们构建了针对大规模创新型竞赛的评审算法体系，如图\ref{fig:评分算法示意图}所示。具体来说：
\begin{enumerate}
	\par
	\item 最优随机交叉分发方案
	
	在大规模竞赛中，当参数作品数目足够庞大，而专家数目有限的情况下，根据参赛作品数目及专家数目，以及每件作品所需的评审分数量，构建无向图；根据无向图的边数因子和分布因子，计算评价指标$w$。若条件允许，可进行多次模拟，在保证分发方案随机性的同时选择评价指标最大的分发方案进行随机交叉分发；
	
	\item 标准分计算公式优化
	
	我们在现有的标准分计算公式上引入自适应因子，根据专家打分集合的分布与正态分布的相关系数来确定相似性，从而控制自适应因子的大小；这能较好的识别和评估各专家打分作品集合的可比性，以削弱专家个人打分偏好的影响，保证分数及排名的理性客观；
	
	\item 多阶段评审
	
	实验分析观察可得，不同阶段的评审分数相对独立，因此多阶段评审可以为评审分数提供更多样本集，从而减小某专家打分的偏差影响，从而使作品所获得的最终分数及排名奖项与其实际水平更加契合；
	
	\item 极差筛选及处理策略
	
	在单阶段评审中，统计所有作品极差的平均值与标准差，明确其数学统计特性；通过阈值$\alpha$筛选需要被修改的具有较大极差的作品，以摒弃极差大但排名靠后的作品，同时进一步筛选出创新型作品样本。
	同时，我们分别对两阶段评审设计极差处理策略，第一阶段极差处理采用首尾剔除法，第二阶段采用反距离加权平均优化算法；
	
	\item 结果分析
	\begin{enumerate}
		\item 通过随机分发模型，相比特制化的滑动窗口分发模型或块匹配分发模型，作品分发对应的无向图的评价指标$\rho$更高，也即此分发模型在所定义的评价指标体系下更优。
		
		\item 在我们提出的标准分计算模型下，通过自适应权重因子，能够较大地去除专家个人因素对所评审作品分数的影响。
		
		\item 通过两阶段评审的方式，可以更好地保证创新性竞赛评审中较有争议作品(大概率是创新性作品)得到公平地评审。
		
		\item 在二阶段通过极差调整策略，减弱大极差评分对最终评分的影响，有利于不同作品评分的相对公平性。
	\end{enumerate}
	
	
\end{enumerate}
\newpage
\section{总结与展望 }
	本文在大规模创新型竞赛的题旨下，分别对竞赛作品的交叉分配方案、评委评分标准分的计算公式、作品所获分数的极差计算及评价、创新型作品的处理等方案建立数学模型并优化模型效果，同时研究分析了两阶段评审成绩分布特点、标准分、极差的分布及改进方法等，进一步提升模型精确程度；通过Python、C++等优秀编程语言以及LaTeX,Drawio等排版、绘图平台全方位、可视化、可读化地展示团队所构建的数学模型，做到多位一体，明确可观。经过模型改正，新模型相比题目原始给出的评分数据，无论从合理性、可比性、相关性还是准确性上都在不同建模阶段体现出良好的提升效果，我们也在多种方法中相互比较，从而优化最终方案，呈现出相对更优秀的效果。
	总体而言，本文基于模拟数据1和数据2，主要完成以下工作：
	\begin{enumerate}
	\item 构建无向图模型，通过无向图边数因子和分布因子来对无向图的结构进行评价，并通过该模型证明了随机分发策略为最优策略。
	\item 通过自适应得分因子，对现有的标准分计算模型进行了改善。通过降低打分具有明显倾向性(即与正态分布的偏离程度大)的专家打分的权重，削弱了专家偏好对作品最终得分的影响。
	\item 基于复议作品的极差分布规律以及复议分变化规律，建立了极差筛选与分数调整模型。由统计规律得到的经验性系数，构建极差阈值探测公式。对于大极差作品，采用反距离加权算法计算作品的最终得分。
	\end{enumerate}
	
	注意到，当前所提出了最优分配策略和评分体系是在作品符合正态分布的假设前提下得到的，当作品不满足正态分布，或者存在其他关于作品或评审专家的先验信息时，更好的方式是构建贝叶斯网络进行建模。这在未来的工作中可以适当地进行探索与研究。

\newpage
%参考文献   手工录入
%\begin{thebibliography}{9}%宽度9
% \bibitem{bib:one} ....
% \bibitem{bib:two} ....
%\end{thebibliography}

%采用bibtex方案
%\cite{mittelbach_latex_2004,wright_latex3_2009,beeton_unicode_2008,vieth_experiences_2009}

\bibliographystyle{gmcm}
\bibliography{ref}


\newpage
%附录
\appendix
%\setcounter{page}{1} %如果需要可以自行重置页码。
\section{源程序}

本论文使用到的编程语言包括：
C++
Python\cite{python2021python}\cite{virtanen2020scipy}\cite{hunter2007matplotlib}
，具体的配置如下表所示。
	\begin{table*}[h]
		\centering
		\caption{代码运行环境配置}
		\label{tab:timing}
		\footnotesize
		\begin{tabular}{c|cc|clrclc}
			\toprule[1 pt]
			\multirow{2}{*}[-0.5ex]{Config.}  & OS name                                            & Ubuntu      & Processor                           & \multicolumn{5}{l}{12th Gen Intel® Core™ i9-12900H × 20}                                                                                                                                  \\ \cmidrule{2-9} 
			& OS type                                            & 64-bit                  & Graphics                            & \multicolumn{5}{l}{Mesa Intel® Graphics (ADL GT2) / Mesa Intel® Graphics (ADL GT2)}                                                                                                       \\ \midrule[1pt]
		\end{tabular}
	\end{table*}
	
\begin{lstlisting}[label=work_class,caption={作品类的数据结构定义}]
enum Award {
    FirAward = 1,
    SedAward = 2,
    ThdAward = 3,
    NoAward = 4
};

struct Work {
    using Ptr = std::shared_ptr<Work>;

    int id;
    std::unordered_map<std::string, Expert> expStage1;
    std::unordered_map<std::string, Expert> expStage2;
    double finalScore;
    double newFinalScore{-1.0};
    Award award;
    int order;
    double maxDisScoreInStage1{-1.0};
    double maxDisScoreInStage2{-1.0};
    double meanStdScoreStage1{-1.0};
    double meanStdScoreStage2{-1.0};

    Work(int id, int order, const std::unordered_map<std::string, Expert> &expertsFir,
         const std::unordered_map<std::string, Expert> &expertsSed,
         double finalScore, Award award)
            : id(id), order(order), expStage1(expertsFir), expStage2(expertsSed), finalScore(finalScore),
              award(award) {}

    void computeFinalScore(double maxMean, double maxStd, bool b = true) {
        double firScore = ExpNewStdScoreMean(expStage1);
        if (b && (maxDisScoreInStage2 > maxMean + maxStd)) {
            double sedScore = InvDisWeightOnExpNewStdScore(expStage2);
            newFinalScore = firScore + 3 * sedScore;
        } else {
            double sum = 0.0;
            for (const auto &item: expStage2) {
                sum += item.second.newStdScore;
            }
            newFinalScore = firScore + sum;
        }
    }

    void setMaxDisScoreInStage1(double maxDisScoreInStage1) {
        Work::maxDisScoreInStage1 = maxDisScoreInStage1;
    }

    void setMaxDisScoreInStage2(double maxDisScoreInStage2) {
        Work::maxDisScoreInStage2 = maxDisScoreInStage2;
    }

    void setMeanStdScoreStage1(double meanStdScoreStage1) {
        Work::meanStdScoreStage1 = meanStdScoreStage1;
    }

    void setMeanStdScoreStage2(double meanStdScoreStage2) {
        Work::meanStdScoreStage2 = meanStdScoreStage2;
    }

    void setMaxDisScore(double maxDisScore) {
        maxDisScoreInStage2 = maxDisScore;
    }

    friend std::ostream &operator<<(std::ostream &os, const Work &work) {
        os << "id: " << work.id << " order: " << work.order << " expStage1: {";
        for (const auto &item: work.expStage1) {
            os << item.second << ", ";
        }
        os << "} expStage2: {";
        for (const auto &item: work.expStage2) {
            os << item.second << ", ";
        }
        os << "} finalScore: " << work.finalScore
           << " newFinalScore: " << work.newFinalScore
           << " award: " << ns_ris::EnumCast::enumToString(work.award);
        return os;
    }
};

\end{lstlisting}

\begin{lstlisting}[label=judge,caption={专家类的数据结构定义}]

struct Expert {
    using Ptr = std::shared_ptr<Expert>;
    std::string id;
    double srcScore;
    double stdScore;
    double newStdScore{-1.0};
    double reScore;
    int stage;
    double weight{-1.0};
    double mu{-1.0};
    double sigma{-1.0};

    Expert(std::string id, double srcScore, double stdScore, int stage, double reScore = -1.0)
            : id(std::move(id)), srcScore(srcScore), stdScore(stdScore), stage(stage), reScore(reScore) {}

    void setWeight(double w) {
        this->weight = w;
    }

    void setMu(double mu) {
        Expert::mu = mu;
    }

    void setSigma(double sigma) {
        Expert::sigma = sigma;
    }

    void setNewStdScore(double newStdScore) {
        Expert::newStdScore = newStdScore;
    }

    void computeNewScore0() {
        newStdScore = 50.0 + 10.0 * (srcScore - mu) / sigma;
    }

    void computeNewScore1() {
        newStdScore = weight * (50.0 + 10.0 * (srcScore - mu) / sigma);
    }

    void computeNewScore2() {
        newStdScore = 50.0 + weight * 10.0 * (srcScore - mu) / sigma;
    }

    friend std::ostream &operator<<(std::ostream &os, const Expert &expert) {
        os << "id: " << expert.id << " srcScore: " << expert.srcScore << " stdScore: " << expert.stdScore
           << " newStdScore: " << expert.newStdScore << " reScore: " << expert.reScore << " stage: " << expert.stage
           << " weight: " << expert.weight << " mu: " << expert.mu << " sigma: " << expert.sigma;
        return os;
    }
};
\end{lstlisting}

\begin{lstlisting}[label=util,caption={工具函数}]

std::vector<std::string> split(const std::string &str, char splitor, bool ignoreEmpty = true) {
    std::vector<std::string> vec;
    auto iter = str.cbegin();
    while (true) {
        auto pos = std::find(iter, str.cend(), splitor);
        auto elem = std::string(iter, pos);
        if (!(elem.empty() && ignoreEmpty)) {
            vec.push_back(elem);
        }
        if (pos == str.cend()) {
            break;
        }
        iter = ++pos;
    }
    return vec;
}

double ExpNewStdScoreMean(const std::unordered_map<std::string, Expert> &exps) {
    double mean = 0.0;
    for (const auto &item: exps) {
        mean += item.second.newStdScore / static_cast<double >(exps.size());
    }
    return mean;
}

double ExpStdScoreMean(const std::unordered_map<std::string, Expert> &exps) {
    double mean = 0.0;
    for (const auto &item: exps) {
        mean += item.second.stdScore / static_cast<double >(exps.size());
    }
    return mean;
}

double ExpReScoreMean(const std::unordered_map<std::string, Expert> &exps) {
    double mean = 0.0;
    for (const auto &item: exps) {
        mean += item.second.reScore / static_cast<double >(exps.size());
    }
    return mean;
}

double InvDisWeightOnExpNewStdScore(const std::unordered_map<std::string, Expert> &exps) {
    double mean = ExpNewStdScoreMean(exps);
    double score = 0.0;
    double wSum = 0.0;
    for (const auto &item: exps) {
        double w = 1.0 / std::pow(item.second.newStdScore - mean, 2);
        score += w * item.second.newStdScore;
        wSum += w;
    }
    score /= wSum;
    return score;
}

double InvDisWeightOnExpStdScore(const std::unordered_map<std::string, Expert> &exps) {
    double mean = ExpStdScoreMean(exps);
    double score = 0.0;
    double wSum = 0.0;
    for (const auto &item: exps) {
        double w = 1.0 / std::pow(item.second.stdScore - mean, 2);
        score += w * item.second.stdScore;
        wSum += w;
    }
    score /= wSum;
    return score;
}

double adaptScore(std::unordered_map<std::string, Expert> exps) {
    auto iter = std::minmax_element(exps.begin(), exps.end(), [](const std::pair<std::string, Expert> &e1,
                                                                 const std::pair<std::string, Expert> &e2) {
        return e1.second.stdScore < e2.second.stdScore;
    });
    exps.erase(iter.first);
    exps.erase(iter.second);
    double mean = ExpStdScoreMean(exps);
    double score = 0.0;
    double wSum = 0.0;
    for (const auto &item: exps) {
        double w = 1.0 / std::pow(item.second.stdScore - mean, 2);
        score += w * item.second.stdScore;
        wSum += w;
    }
    score /= wSum;
    return score;
}

double MaxDisOnExpNewStdScore(const std::unordered_map<std::string, Expert> &exps) {
    auto [iter1, iter2] = std::minmax_element(exps.begin(), exps.end(),
                                              [](const std::pair<std::string, Expert> &e1,
                                                 const std::pair<std::string, Expert> &e2) {
                                                  return e1.second.newStdScore < e2.second.newStdScore;
                                              });
    return std::abs(iter1->second.newStdScore - iter2->second.newStdScore);
}

double MaxDisOnExpStdScore(const std::unordered_map<std::string, Expert> &exps) {
    auto [iter1, iter2] = std::minmax_element(exps.begin(), exps.end(),
                                              [](const std::pair<std::string, Expert> &e1,
                                                 const std::pair<std::string, Expert> &e2) {
                                                  return e1.second.stdScore < e2.second.stdScore;
                                              });
    return std::abs(iter1->second.stdScore - iter2->second.stdScore);
}

double StrScoreMapping(const std::string &str) {
    double score = -1.0;
    try {
        score = str.empty() ? -1.0 : std::stod(str);
    } catch (...) {
        std::cout << "error " << str << ',' << str.empty() << std::endl;
    }
    return score;
}

double Similarity(const std::vector<int> &o1, std::vector<int> &o2) {
    LOG_VAR(o1.size(), o2.size())
    auto n = o1.size();
    double dis = 0.0;
    for (int i = 0; i < n; ++i) {
        dis += std::abs(o1.at(i) - o2.at(i));
    }
    LOG_VAR(dis)
    return 1.0 / (1.0 + std::log((dis + 1)) / n);
}

double meanCal(const std::vector<double> &works) {
    double mean = 0.0;
    for (const auto &item: works) {
        mean += item / static_cast<double>(works.size());
    }
    return mean;
}

double stdCal(const std::vector<double> &works) {
    double mean = meanCal(works);
    double std = 0.0;
    for (const auto &item: works) {
        std += 1.0 / (static_cast<double>(works.size()) - 1.0) * std::pow(mean - item, 2.0);
    }
    return std::sqrt(std);
}
\end{lstlisting}

\begin{lstlisting}[label=数据io,caption={数据读取}]
std::ifstream file("/home/csl/CppWorks/toys/math_model/data/data1.csv");
    std::string str;
    int workId = 0;
    std::vector<Work> works;
    while (std::getline(file, str)) {
        str.pop_back();
        auto items = split(str, ',', false);
//        LOG_VAR(str)
//        LOG_VAR(items.size())
//        std::cin.get();
        std::unordered_map<std::string, Expert> expertsFir;
        // stage1
        for (int i = 0; i < 5; ++i) {
            Expert e(
                    items.at(5 + i * 3 + 0),
                    StrScoreMapping(items.at(5 + i * 3 + 1)),
                    StrScoreMapping(items.at(5 + i * 3 + 2)),
                    1);
            expertsFir.insert({e.id, e});
        }
        // stage2
        std::unordered_map<std::string, Expert> expertsSed;
        for (int i = 0; i < 3; ++i) {
            Expert e(items.at(23 + i * 4 + 0), StrScoreMapping(items.at(23 + i * 4 + 1)),
                     StrScoreMapping(items.at(23 + i * 4 + 2)), 2, StrScoreMapping(items.at(23 + i * 4 + 3)));
            expertsSed.insert({e.id, e});
        }
        Work w(workId++, std::stoi(items.at(1)), expertsFir, expertsSed, std::stod(items.front()),
               ns_ris::EnumCast::stringToEnum<Award>(items.at(2)));
        works.push_back(w);
//        LOG_VAR(w)
    }
    file.close();

    for (auto &item: works) {
        item.expStage1.erase("");
        item.expStage2.erase("");
    }
\end{lstlisting}

\begin{lstlisting}[label=问题1,caption={问题1代码}]
	std::vector<std::shared_ptr<Work>> works;
    std::vector<std::shared_ptr<Judge>> judges;

    for (int i = 0; i != 3000; ++i) {
        works.push_back(std::make_shared<Work>());
    }
    for (int i = 0; i != 125; ++i) {
        judges.push_back(std::make_shared<Judge>());
    }
    // ----------
    // random selection
    // ----------
    //    std::default_random_engine engine(std::chrono::steady_clock::now().time_since_epoch().count());
    //    for (auto &work: works) {
    //        auto selected = samplingWoutReplace2(engine, judges, 5);
    //        work->judges = selected;
    //        for (const auto &item: selected) {
    //            item->works.push_back(work);
    //        }
    //    }
    
    // ----------
    // split selection
    // ----------
    //    std::vector<Judge::Ptr> judgePool = judges;
    //    std::vector<Work::Ptr> workPool = works;
    //    std::default_random_engine engine(std::chrono::steady_clock::now().time_since_epoch().count());
    //    for (int i = 0; i < 25; ++i) {
    //        auto selectedJudges = samplingWoutReplace2(engine, judgePool, 5);
    //        auto selectedWorks = samplingWoutReplace2(engine, workPool, 120);
    //        for (const auto &item: selectedWorks) {
    //            item->judges = selectedJudges;
    //        }
    //        for (const auto &item: selectedJudges) {
    //            item->works = selectedWorks;
    //        }
    //        for (const auto &item: selectedWorks) {
    //            workPool.erase(std::remove_if(workPool.begin(), workPool.end(), [&item](const Work::Ptr &w) {
    //                return w->id == item->id;
    //            }), workPool.cend());
    //        }
    //        for (const auto &item: selectedJudges) {
    //            judgePool.erase(std::remove_if(judgePool.begin(), judgePool.end(), [&item](const Judge::Ptr &j) {
    //                return j->id == item->id;
    //            }), judgePool.cend());
    //        }
    //    }
    // ---------
    // ring selection
    // ---------
    //    int curFirJudgeIdx = 0;
    //    for (const auto &work: works) {
    //        int i1 = (curFirJudgeIdx) % judges.size();
    //        int i2 = (i1 + 1) % judges.size();
    //        int i3 = (i2 + 1) % judges.size();
    //        int i4 = (i3 + 1) % judges.size();
    //        int i5 = (i4 + 1) % judges.size();
    //
    //        std::vector<Judge::Ptr> selected{
    //                judges.at(i1),
    //                judges.at(i2),
    //                judges.at(i3),
    //                judges.at(i4),
    //                judges.at(i5),
    //        };
    //        work->judges = selected;
    //        for (const auto &item: selected) {
    //            item->works.push_back(work);
    //        }
    //
    //        ++curFirJudgeIdx;
    //    }

    std::vector<std::pair<Judge::Ptr, Judge::Ptr>> group1, group2;
    for (int i = 0; i < judges.size(); ++i) {
        for (int j = i + 1; j < judges.size(); ++j) {
            auto j1 = judges.at(i);
            auto j2 = judges.at(j);
            auto intersection = vectors_intersection(j1->works, j2->works);
            if (intersection.empty()) {
                group1.emplace_back(j1, j2);
            } else {
                group2.emplace_back(j1, j2);
            }
        }
    }
    auto ng1 = group1.size(), ng2 = group2.size();
    double g2Mean = 0.0;
    for (const auto &[j1, j2]: group2) {
        auto intersection = vectors_intersection(j1->works, j2->works);
        g2Mean += static_cast<double>(intersection.size()) / static_cast<double>(ng2);
    }
    double g2Std = 0.0;
    for (const auto &[j1, j2]: group2) {
        auto intersection = vectors_intersection(j1->works, j2->works);
        g2Std += std::pow(static_cast<double>(intersection.size()) - g2Mean, 2.0) / (static_cast<double>(ng2) - 1.0);
    }
    g2Std = std::sqrt(g2Std);
    double f1 = static_cast<double >(ng2) / ((ng1 + ng2));
    double f2 = 1.0 / ((1.0 + g2Std));
    double f3 = ng2 / ((1.0 + g2Std) * (ng1 + ng2));
    return {f1, f2, f3};
\end{lstlisting}

\begin{lstlisting}[label=问题2,caption={问题2代码}]
    works.erase(std::remove_if(works.begin(), works.end(), [](const Work &w) {
        return w.expStage2.empty();
    }), works.end());
    {
        std::ofstream stage1("../data/all_std_scores_in_stage1.csv");
        for (const auto &item: works) {
            for (const auto &item2: item.expStage1) {
                stage1 << item2.second.stdScore << std::endl;
            }
        }
    }
    {
        std::ofstream stage2("../data/all_std_scores_in_stage2.csv");
        for (const auto &item: works) {
            for (const auto &item2: item.expStage1) {
                stage2 << item2.second.stdScore << std::endl;
            }
        }
    }
    {
        std::ifstream stage1("/home/csl/CppWorks/toys/math_model/data/weights_stage1.csv");
        std::string strLine;
        while (std::getline(stage1, strLine)) {
            auto items = split(strLine, ',', false);
//            LOG_VAR(items)
            for (auto &item: works) {
                auto iter = item.expStage1.find(items.front());
                if (iter != item.expStage1.cend()) {
                    iter->second.setWeight(std::stod(items.at(1)));
                    iter->second.setMu(std::stod(items.at(2)));
                    iter->second.setSigma(std::stod(items.at(3)));
                }
            }
        }
        std::ifstream stage2("/home/csl/CppWorks/toys/math_model/data/weights_stage2.csv");
        while (std::getline(stage2, strLine)) {
            auto items = split(strLine, ',', false);
//            LOG_VAR(items)
            for (auto &item: works) {
                auto iter = item.expStage2.find(items.front());
                if (iter != item.expStage2.cend()) {
                    iter->second.setWeight(std::stod(items.at(1)));
                    iter->second.setMu(std::stod(items.at(2)));
                    iter->second.setSigma(std::stod(items.at(3)));
                }
            }
        }
    }
    {
        for (auto &item: works) {
            for (auto &item2: item.expStage1) {
                item2.second.computeNewScore2();
            }
            for (auto &item2: item.expStage2) {
                item2.second.computeNewScore2();
            }
        }
        std::vector<double> maxDisVec;
        for (auto &item: works) {
            item.setMaxDisScore(MaxDisOnExpNewStdScore(item.expStage2));
            maxDisVec.push_back(item.maxDisScoreInStage2);
        }
        double maxDisScoreMean = meanCal(maxDisVec), maxDisScoreStd = stdCal(maxDisVec);
        for (auto &item: works) {
            item.computeFinalScore(maxDisScoreMean, maxDisScoreStd);
        }
        std::vector<int> oldIdx, newIdx;
        for (const auto &item: works) {
            oldIdx.push_back(item.id);
        }
        std::sort(works.begin(), works.end(), [](const Work &w1, const Work &w2) {
            return w1.newFinalScore > w2.newFinalScore;
        });
        for (const auto &item: works) {
            newIdx.push_back(item.id);
        }
        LOG_VAR(oldIdx)
        LOG_VAR(newIdx)
        LOG_VAR(Similarity(oldIdx, newIdx))
        LOG_VAR(Similarity(oldIdx, oldIdx))
        {
            std::ofstream file2("../data/score_2_order.csv");
            for (int i = 0; i < oldIdx.size(); ++i) {
                file2 << oldIdx.at(i) << ',' << newIdx.at(i) << std::endl;
            }

        }
    }
\end{lstlisting}

\begin{lstlisting}[label=问题3,caption={问题3代码}]
    {
        std::ofstream reScoreHighFile("../data/reScoreHigh.csv");
        for (const auto &item: reScoreHigh) {
            for (const auto &item2: item.expStage2) {
                reScoreHighFile << item2.second.stdScore << ',';
            }
            reScoreHighFile << std::endl;
        }
    }
    {
        std::ofstream reScoreLowFile("../data/reScoreLow.csv");
        for (const auto &item: reScoreLow) {
            for (const auto &item2: item.expStage2) {
                reScoreLowFile << item2.second.stdScore << ',';
            }
            reScoreLowFile << std::endl;
        }
    }
    {
        std::ofstream stage1("../data/all_max_dis_scores_in_stage1.csv");
        for (const auto &item: works) {
            stage1 << item.maxDisScoreInStage1 << std::endl;
            for (const auto &item2: item.expStage1) {
                stage1 << item2.second.stdScore << std::endl;
            }
        }
    }
    {
        std::ofstream stage2("../data/all_max_dis_scores_in_stage2.csv");
        for (const auto &item: works) {
            stage2 << item.maxDisScoreInStage2 << std::endl;
            for (const auto &item2: item.expStage2) {
                stage2 << item2.second.stdScore << std::endl;
            }
        }
    }
    {
        std::sort(works.begin(), works.end(), [](const Work &w1, const Work &w2) {
            return w1.order < w2.order;
        });
        std::ofstream maxDis("../data/order_max_dis_stage1.csv");
        for (const auto &item: works) {
            maxDis << item.order << ',' << item.maxDisScoreInStage1 << std::endl;
        }
    }
    {
        works.erase(std::remove_if(works.begin(), works.end(), [](const Work &w) {
            return w.expStage2.empty();
        }), works.end());

        std::sort(works.begin(), works.end(), [](const Work &w1, const Work &w2) {
            return w1.order < w2.order;
        });
        std::ofstream maxDis("../data/order_max_dis_stage2.csv");
        for (const auto &item: works) {
            maxDis << item.order << ',' << item.maxDisScoreInStage2 << std::endl;
        }
        std::ofstream meanTwoStages("../data/mean_two_stages.csv");
        for (const auto &item: works) {
            meanTwoStages << item.order << ',' << item.meanStdScoreStage1 << ',' << item.meanStdScoreStage2
                          << std::endl;
        }
    }
\end{lstlisting}

\begin{lstlisting}[label=问题4,caption={问题4代码}]
works.erase(std::remove_if(works.begin(), works.end(), [](const Work &w) {
        return w.expStage2.empty();
    }), works.end());

    for (auto &item: works) {
        item.setMeanStdScoreStage1(ExpStdScoreMean(item.expStage1));
        item.setMaxDisScoreInStage1(MaxDisOnExpStdScore(item.expStage1));
        if (item.expStage2.empty()) {
            continue;
        }
        item.setMeanStdScoreStage2(ExpStdScoreMean(item.expStage2));
        item.setMaxDisScoreInStage2(MaxDisOnExpStdScore(item.expStage2));
    }
    std::vector<double> range;
    for (const auto &item: works) {
        range.push_back(item.maxDisScoreInStage1);
    }
    auto rangeMean = meanCal(range);
    auto rangeStd = stdCal(range);
    LOG_VAR(rangeMean, rangeStd, works.size())
    for (auto &item: works) {
        double score = 0.0;
        if (item.maxDisScoreInStage1 > rangeMean + 0.745 * rangeStd) {
            score = adaptScore(item.expStage1);
        } else {
            score = ExpStdScoreMean(item.expStage1);
        }
        item.newFinalScore = ExpStdScoreMean(item.expStage1);
//        item.newFinalScore = item.meanStdScoreStage1 + 3.0 * item.meanStdScoreStage2;
    }
    std::sort(works.begin(), works.end(), [](const Work &w1, const Work &w2) {
        return w1.newFinalScore > w2.newFinalScore;
    });
    int count = 0;
    for (const auto &item: works) {
        if (item.maxDisScoreInStage1 > rangeMean + 0.745 * rangeStd) {
            std::cout << item.id << ',' << count << std::endl;
        }
        ++count;
    }
\end{lstlisting}

\end{document} 