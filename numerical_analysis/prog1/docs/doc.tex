\documentclass[12pt, onecolumn]{article}

% 引入相关的包
\usepackage{amsmath, listings, fontspec, geometry, graphicx, ctex, color, subfigure, amsfonts, amssymb}
\usepackage{multirow}
\usepackage[table,xcdraw]{xcolor}
\usepackage[ruled]{algorithm2e}
\usepackage[hidelinks]{hyperref}

		\usepackage{graphicx}
		\usepackage[most]{tcolorbox}
\hypersetup{
	colorlinks=true,
	linkcolor=red,
	citecolor=red,
}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{picins}

% 设定页面的尺寸和比例
\geometry{left = 1.5cm, right = 1.5cm, top = 1.5cm, bottom = 1.5cm}

% 设定两栏之间的间距
\setlength\columnsep{1cm}

% 设定字体，为代码的插入作准备
\newfontfamily\ubuntu{Ubuntu Mono}
\newfontfamily\consolas{Consolas}

% 代码块的风格设定
\lstset{
	language=C++,
	basicstyle=\small\ubuntu,
	keywordstyle=\textbf,
	stringstyle=\itshape,
	commentstyle=\itshape,
	numberstyle=\scriptsize\ubuntu,
	showstringspaces=false,
	numbers=left,
	numbersep=8pt,
	tabsize=2,
	frame=single,
	framerule=1pt,
	columns=fullflexible,
	breaklines,
	frame=shadowbox, 
	backgroundcolor=\color[rgb]{0.97,0.97,0.97}
}

% 字体族的定义
% \fangsong \songti \heiti \kaishu
\newcommand\normf{\fangsong}
\newcommand\boldf{\heiti}
\newcommand\keywords[1]{\boldf{关键词：} \normf #1}

\newcommand\liehat[1]{\left[ #1 \right]_\times}
\newcommand\lievee[1]{\left[ #1 \right]^\vee}
\newcommand\liehatvee[1]{\left[ #1 \right]^\vee_\times}

\newcommand\mlcomment[1]{\iffalse #1 \fi}
%\newcommand\mlcomment[1]{ #1 }

\newcounter{problemname}
\newenvironment{problem}{\stepcounter{problemname}\par\noindent\normf\textbf{\textcolor[rgb]{1,0,0}{题目\arabic{problemname}.} }}{\leavevmode\\\par}
\newenvironment{solution}{\par\noindent\normf\textbf{解答: }}{\leavevmode\\\par}
\newenvironment{note}{\par\noindent\normf\textbf{题目\arabic{problemname}的注记: }}{\leavevmode\\\par}


\begin{document}
	\begin{titlepage}
	    \centering
	    \includegraphics[width=0.4\textwidth]{whu_red.png}\par\vspace{1cm}
	    \vspace{4cm}
	    {\huge\kaishu “数值分析”编程作业\par 线性方程组$\boldsymbol{Ax}=\boldsymbol{b}$的求解 \par}
	    \vspace{3cm}
	    {\Large\kaishu 
	    \begin{center}\begin{tabular}{l}
	    姓名：陈烁龙\\
	    学号：\bfseries 2023202140019\\
	    学院：测绘学院
	    \end{tabular}\end{center}
	     \par}
	    
	
	    \vfill
	
	% Bottom of the page
	    {\large\kaishu\bfseries \today\par}
	\end{titlepage}
		% 换页
 		\thispagestyle{empty}
		\clearpage
		
		% 插入目录、图、表并换页
		\pagenumbering{roman}
		\tableofcontents
		\newpage
%		\listoffigures
%		\newpage
		\listoftables
		% 罗马字母形式的页码
		
		\clearpage
		% 从该页开始计数
		\setcounter{page}{1}
		% 阿拉伯数字形式的页码
		\pagenumbering{arabic}
	
	\section{\normf{代码运行环境说明}}
	
		\normf
		表\ref{tab:代码运行环境}显示了本次编程测试的运行环境。本次代码使用\emph{CPP 17}实现，使用到了线性代数库\emph{Eigen}。代码虽然在\emph{Ubuntu}上实现， 但由于是\emph{Cmake}架构的项目，所以具有跨平台的特征，即可以在\emph{Windows}平台和\emph{Mac}上编译运行。
		
		绘图使用\emph{Python}中的\emph{matploylib}库实现，具体的绘图脚本在\emph{script}文件夹下。
		
		% Please add the following required packages to your document preamble:
		% \usepackage{multirow}
		\begin{table}[h]
		\centering
		\caption{\normf 代码运行环境}
		\label{tab:代码运行环境}
		\vspace{2mm}
		\begin{tabular}{ccc|cl}
		\toprule
		\multicolumn{1}{c|}{\multirow{2}{*}{Config.}} & OS name & Ubuntu 20.04.6 LTS & Processor              & 12th Gen Intel® Core™ i9-12900H × 20              \\ \cmidrule{2-5} 
		\multicolumn{1}{c|}{}                         & OS Type & 64-bit             & Graphics               & Mesa Intel® Graphics (ADL GT2)                    \\ \midrule[1pt]\midrule[1pt]
		\multicolumn{3}{c|}{Library}                                                 & \multicolumn{2}{c}{Link}                                                   \\ \midrule
		\multicolumn{3}{c|}{Eigen3}                                                  & \multicolumn{2}{c}{https://eigen.tuxfamily.org/index.php?title=Main\_Page}              \\ \bottomrule
		\end{tabular}
		\end{table}
		
	\section{\normf{LU分解}}
	\subsection{\normf{算法描述}}
	对于线性方程组$\boldsymbol{Ax=b}$中的系数方阵$\boldsymbol{A}$，可以通过将其进行LU分解，得到：
	\begin{equation}
	\boldsymbol{A}=\boldsymbol{LU}
	\end{equation}
	而后在方程求解的过程中，使用杜利特尔(Doolittle)分解求解线性方程组：
	\begin{equation}
	\boldsymbol{Ax}=\boldsymbol{b}\quad\Rightarrow\quad
	\boldsymbol{LUx}=\boldsymbol{b}\quad\Rightarrow\quad
	\boldsymbol{Ly}=\boldsymbol{b}\quad\Rightarrow\quad
	\boldsymbol{Ux}=\boldsymbol{y}\quad\Rightarrow\quad
	\boldsymbol{x}
	\end{equation}
	
	关于矩阵$\boldsymbol{A}$的LU分解方面，在进行高斯消去的过程中，初等行变换过程相当于左乘初等变换矩阵。对于第$k$次变换，相当于左乘：
	\begin{equation}
	\boldsymbol{L}_k=\begin{pmatrix}
	1\\
	0&1\\
	0&-l_{k+1,k}&1\\
	\cdots\\
	0&-l_{n,k}&0&\cdots&1
	\end{pmatrix}
	\quad
	\boldsymbol{L}_k^{-1}=\begin{pmatrix}
		1\\
		0&1\\
		0&l_{k+1,k}&1\\
		\cdots\\
		0&l_{n,k}&0&\cdots&1
		\end{pmatrix}
	\end{equation}
	其中$l_{i,k}=a^{(k)}_{i,k}/a^{(k)}_{k,k},i\in[k+1,n]$。于是，有：
	\begin{equation}
	\boldsymbol{A}^{(1)}=\boldsymbol{L}_1^{-1}\cdot\boldsymbol{L}_2^{-1}\cdots
	\boldsymbol{L}_n^{-1}=\boldsymbol{L}\boldsymbol{A}^{n}=\boldsymbol{LU}
	\end{equation}
	
	当然，在高斯消去法消去过程中可能出现$a_{k,k}^{k}=0$的情况，这时高斯消去法将无法进行。这时，可以在第k步消元前，在系数矩阵第k列的对角线以下的元素中找出绝对值最大的元，再继续消去计算，也即使用列主元Gauss消去法。
	
	
	\subsection{\normf{实验结果}}
	\subsubsection{\normf{小型随机矩阵测试}}
	$5\times 5$的系数矩阵$\boldsymbol{A}$:
	\begin{equation}
	\boldsymbol{A}=\begin{pmatrix}
	 0.68038 &-0.60490 &-0.04521&  0.83239& -0.96740\\
	-0.21123 &-0.32955 & 0.25774&  0.27142& -0.51423\\
	 0.56620 & 0.53646 &-0.27043&  0.43459& -0.72554\\
	 0.59688 &-0.44445 & 0.02680& -0.71679&  0.60835\\
	 0.82329 & 0.10794 & 0.90446&  0.21394& -0.68664\\
	\end{pmatrix}
	\end{equation}
	系数矩阵$\boldsymbol{A}$的LU分解结果：
	\begin{equation}
	\boldsymbol{L}=\begin{pmatrix}
	 1.00000&  0.00000&  0.00000&  0.00000 & 0.00000\\
	-0.31047&  1.00000&  0.00000&  0.00000 & 0.00000\\
	 0.83219& -2.00993&  1.00000&  0.00000 & 0.00000\\
	 0.87728& -0.16664&  0.41659&  1.00000 & 0.00000\\
	 1.21006& -1.62345&  5.27118&  2.46993 & 1.00000\\
	\end{pmatrix}
	\end{equation}
	\begin{equation}
	\boldsymbol{U}=\begin{pmatrix}
	 0.68038& -0.60490& -0.04521 & 0.83239& -0.96740\\
	 0.00000& -0.51736&  0.24371 & 0.52985& -0.81457\\
	 0.00000&  0.00000&  0.25702 & 0.80686& -1.55771\\
	 0.00000&  0.00000&  0.00000 &-1.69487&  1.97022\\
	 0.00000&  0.00000&  0.00000 & 0.00000&  2.50623\\
	\end{pmatrix}
	\end{equation}
	真值：
	\begin{equation}
	\boldsymbol{x}_{gt}^\top=\begin{pmatrix}
	-0.19811 &-0.74042& -0.78238 & 0.99785& -0.56349
	\end{pmatrix}
	\end{equation}
	解算结果：
	\begin{equation}
	\boldsymbol{x}_{sl}^\top=\begin{pmatrix}
	-0.19811 &-0.74042& -0.78238 & 0.99785& -0.56349
	\end{pmatrix}
	\end{equation}
	验证了算法的正确性。
	
	\subsubsection{\normf{大型随机矩阵测试}}
	通过随机函数，构建了一个$1000\times 1000$的随机矩阵，并使用所实现的算法进行了求解，统计其平均运行时间和计算误差，结果如下：
	% Please add the following required packages to your document preamble:
	% \usepackage{multirow}
	\begin{table}[h]
	\normf
	\centering
	\caption{\normf{测试结果}}
	\vspace{2mm}
	\begin{tabular}{c|ccc}
	\toprule
	\multirow{2}{*}{矩阵维数} & \multicolumn{2}{c}{运行时间（秒）} & \multirow{2}{*}{计算误差} \\ \cmidrule{2-3}
	                      & LU分解        & 方程求解（LU分解+回代） &                       \\ \midrule
	10                    & 5.89340e-06 & 1.43406e-05   & 4.82033e-15           \\
	100                   & 4.22002e-03 & 4.24337e-03   & 5.08518e-12           \\
	1000                  & 3.37420e+1  & 3.37437e+1    & 4.03739e-10           \\ \bottomrule
	\end{tabular}
	\end{table}
	
	由于该算法的计算量主要集中在LU分解，其时间复杂度为$\mathcal{O}(n^2)$，所以当矩阵的维数增加时，运行时间显著增加。由于计算机的舍入误差，当矩阵的维数增加时，计算次数增加，相应的误差也增加。
	
	基于上述实验，可以得到：
	\begin{enumerate}
	\item LU分解可以避免高斯消元法中的多次除法运算，提高计算效率。
	
	\item LU分解可以重复利用分解后的矩阵，对于同一个系数矩阵但不同的右端项，只需要进行一次前向和后向替换，而不需要重新分解。
	
	\item LU分解需要额外的存储空间来保存分解后的矩阵，占用了内存资源。
	
	\item LU分解对于奇异矩阵或接近奇异的矩阵可能失败或不稳定，需要进行部分或完全主元选取，增加了计算复杂度。
	
	\item LU分解对于大规模的稀疏矩阵可能导致填充现象，即分解后的矩阵比原矩阵更稠密，造成存储和计算的浪费。
	\end{enumerate}
	
	\subsection{\normf{关键代码}}
	\begin{lstlisting}[caption=\normf 对矩阵$\boldsymbol{A}$的LU分解]
    void LUFactorization(const Eigen::MatrixXd &AMat, Eigen::MatrixXd &LMat, Eigen::MatrixXd &UMat) {
        assert(AMat.rows() == AMat.cols());
        auto n = AMat.rows();

        LMat = Eigen::MatrixXd::Identity(n, n);
        UMat = AMat;
        for (int c = 0; c < n - 1; ++c) {
            Eigen::MatrixXd curLMatInv = Eigen::MatrixXd::Identity(n, n);
            for (int r = c + 1; r < n; ++r) {
                double l = UMat(r, c) / UMat(c, c);
                curLMatInv(r, c) = l;
                UMat.row(r) = UMat.row(r) - l * UMat.row(c);
            }
            LMat = LMat * curLMatInv;
        }
    }
	\end{lstlisting}
	
	\begin{lstlisting}[caption=杜利特尔(Doolittle)分解求解线性方程组]
	 void EquSolvingByLU(const Eigen::MatrixXd &AMat, const Eigen::VectorXd &bVec, Eigen::VectorXd &xVec) {
	     assert(AMat.rows() == AMat.cols());
	     assert(AMat.rows() == bVec.rows());
	     auto n = AMat.rows();
	
	     Eigen::MatrixXd LMat, UMat;
	     ns_na::LUFactorization(AMat, LMat, UMat);
	     // A = LU, LUx = b, Ly = b, Ux = y
	     // ------
	     // Ly = b
	     // ------
	     Eigen::VectorXd yVec(n);
	     yVec(0) = bVec(0) / LMat(0, 0);
	     for (int r = 1; r < n; ++r) {
	         yVec(r) = bVec(r) - (LMat.block(r, 0, 1, r) * yVec.block(0, 0, r, 1))(0, 0);
	     }
	     // ------
	     // Ux = y
	     // ------
	     xVec = Eigen::VectorXd(n);
	     xVec(n - 1) = yVec(n - 1) / UMat(n - 1, n - 1);
	     for (int r = static_cast<int>(n) - 2; r >= 0; --r) {
	         xVec(r) = (yVec(r) - (UMat.block(r, r + 1, 1, n - r - 1)
	                               * xVec.block(r + 1, 0, n - r - 1, 1))(0, 0)) / UMat(r, r);
	     }
	 }
	\end{lstlisting}
	
	\newpage
	\section{\normf{最速梯度下降}}
	\subsection{\normf{算法描述}}
	若系数矩阵$\boldsymbol{A}$为对称正定矩阵，则求解线性方程组$\boldsymbol{Ax}=\boldsymbol{b}$等价于求解二次函数$f(\boldsymbol{x})=0.5\times \boldsymbol{x}^\top\boldsymbol{A}\boldsymbol{x}-\boldsymbol{b}^\top\boldsymbol{x}$的极小点。
	
	对$f(\boldsymbol{x})$求导，得到负梯度方向：
	\begin{equation}
	\boldsymbol{p}=-\triangledown f(\boldsymbol{x})=\boldsymbol{b}-\boldsymbol{A}\boldsymbol{x}=\boldsymbol{r}
	\end{equation}
	为了使得下降后的函数最小，即求解：
	\begin{equation}
	g(\alpha)=f(\boldsymbol{x}+\alpha\boldsymbol{r})
	=0.5\times\left( \boldsymbol{x}+\alpha\boldsymbol{r}\right) ^\top\boldsymbol{A}\left( \boldsymbol{x}+\alpha\boldsymbol{r}\right)
	-\boldsymbol{b}^\top\left( \boldsymbol{x}+\alpha\boldsymbol{r}\right)
	\end{equation}
	的最小值对应的$\alpha$。由于：
	\begin{equation}
	g^\prime(\alpha)=\alpha\boldsymbol{r}^\top\boldsymbol{A}\boldsymbol{r}-\boldsymbol{r}^\top\boldsymbol{r}
	\end{equation}
	且有：
	\begin{equation}
	g^\prime\prime(\alpha)=\boldsymbol{r}^\top\boldsymbol{A}\boldsymbol{r}>0
	\end{equation}
	所以最小值在$g^\prime(\alpha)=0$处取得，即有：
	\begin{equation}
	\alpha=\frac{\boldsymbol{r}^\top\boldsymbol{r}}{\boldsymbol{r}^\top\boldsymbol{A}\boldsymbol{r}}
	\end{equation}
	所以每次对$\boldsymbol{x}$向量的更新量为：
	\begin{equation}
	\boldsymbol{x}_{k+1}\gets\boldsymbol{x}_{k}+\alpha_k\cdot\boldsymbol{r}_{k}
	\end{equation}
	对$\boldsymbol{r}_k$的更新为：
	\begin{equation}
	\boldsymbol{r}_{k+1}=\boldsymbol{b}-\boldsymbol{A}\boldsymbol{x}_{k+1}=
	\boldsymbol{b}-\boldsymbol{A}\left( \boldsymbol{x}_{k}+\alpha_k\cdot\boldsymbol{r}_{k}\right) =
	\boldsymbol{r}_k-\alpha\boldsymbol{A}\boldsymbol{r}_k
	\end{equation}
	
	\subsection{\normf{实验结果}}
	\subsubsection{\normf{小型矩阵测试}}
	设要求解的线性方程组为：
	\begin{equation}
	\begin{pmatrix}
	3&2\\2&6
	\end{pmatrix}\boldsymbol{x}=\begin{pmatrix}
	2\\-8
	\end{pmatrix}
	\end{equation}
	迭代的初始值$\boldsymbol{x}^{(0)}$选取两种：
	\begin{equation}
	\boldsymbol{x}_0^{(0)}=\begin{pmatrix}
	-2&-2
	\end{pmatrix}^\top
	\quad
	\boldsymbol{x}_1^{(0)}=\begin{pmatrix}
		5&2
		\end{pmatrix}^\top
	\end{equation}
	
	图\ref{fig:最速下降法迭代过程图}描述了该测试案例中的迭代过程，其中左图对于第一种初值选取，右图对应第二种初值选取。可以看到对于不同的初值，迭代的步长和步数都存在较大的差异。在最开始的时候，迭代的步长较大，而后逐渐减小并逼近真值：
	\begin{equation}
	\boldsymbol{x}_{gt}=\begin{pmatrix}
	2,-2
	\end{pmatrix}^\top
	\end{equation}
		\begin{figure}[h]
			\centering
			\includegraphics[width=0.48\linewidth]{../img/steep_desc_1.pdf}
			\includegraphics[width=0.48\linewidth]{../img/steep_desc_2.pdf}
			\caption{\normf 不同初值下的最速下降法迭代过程图}
			\label{fig:最速下降法迭代过程图}
		\end{figure}
	
	\subsubsection{\normf{大型稀疏矩阵测试}}
	通过构建形如：
	\begin{equation}
	\boldsymbol{A}=\begin{pmatrix}
	2&-1&0&&&\cdots\\
	-1&2&-1&0&&\cdots\\
	0&-1&2&-1&0&\cdots\\
	&&\cdots\\
	&&\cdots&-1&2&-1\\
	&&\cdots&&-1&2
	\end{pmatrix}
	\end{equation}
	的系数矩阵，而后随机生成$\boldsymbol{x}$向量，进而得到$\boldsymbol{b}$向量。解向量的初值设为零向量。
	
	本次一共测试了三种维度的矩阵：$10\times 10$、$100\times 100$和$1000\times 1000$的矩阵。结果如下表所示。相较于“LU分解法”相比，运行时间更少(同时应该考虑迭代终止阈值的设置)。“迭代求解法”相较于“LU分解法”可操控性更强，可以通过改变迭代终止阈值，在计算精度和计算效率两个方面进行权衡，这对于实时性的应用尤为重要。但是需要注意的是，这种迭代方法的初值选取较为重要，影响着迭代步数。
	\begin{table}[h]
	\normf
	\centering
	\caption{\normf 测试结果}
	\vspace{2mm}
	\begin{tabular}{c|cccc}
	\toprule
	矩阵维数 & 迭代次数  & 迭代阈值  & 运行时间（秒）     & 计算误差        \\ \midrule
	10   & 473   & 1e-10 & 3.62630e-05 & 1.66156e-09 \\
	100  & 30375 & 1e-10 & 6.37322e-03 & 1.51287e-07 \\
	1000 & 41218 & 1e-10 & 4.33385e-00 & 1.71437e-01 \\ \bottomrule
	\end{tabular}
	\end{table}
	
		
		基于上述实验，可以得到：
		\begin{enumerate}
		\item 当目标函数为二次函数时，“最速下降法”具有二阶收敛速度。
		
		\item 收敛速度并不快，因为最速下降方向仅仅是指某点的一个局部性质。
		
		\item 在接近极小点时，步长越来越小，移动越来越慢，导致最速下降法的收敛速度很慢。
		
		\item 在某些情况下，可能出现锯齿现象，即相邻两次迭代的方向互相垂直，使得迭代点曲折前进。
		
		\item 对于非二次函数，可能存在震荡或者停滞现象。
		\end{enumerate}
	
	\subsection{\normf{关键代码}}
	\begin{lstlisting}[caption=\normf{最速下降法代码}]
    void steepest_descent(const Eigen::MatrixXd &AMat, const Eigen::VectorXd &bVec, const Eigen::VectorXd &xVec0,
                          Eigen::VectorXd &xVec, double thresh) {
        xVec = xVec0;
        Eigen::VectorXd rVec = bVec - AMat * xVec;
        while (true) {
            LOG_VAR(xVec.transpose())
            Eigen::VectorXd ar = AMat * rVec;
            double alpha = rVec.dot(rVec) / rVec.dot(ar);
            xVec = xVec + alpha * rVec;
            if (alpha * rVec.squaredNorm() < thresh) {
                break;
            }
            rVec = rVec - alpha * ar;
        }
    }
	\end{lstlisting}
	
	\newpage
	\section{\normf{共轭梯度下降}}
	\subsection{\normf{算法描述}}
	对于线性方程组$\boldsymbol{A}\boldsymbol{x}=\boldsymbol{b}$，设：
	\begin{equation}
	\boldsymbol{p}_0,\boldsymbol{p}_1,\cdots,\boldsymbol{p}_{n-1}
	\end{equation}
	为矩阵$\boldsymbol{A}$的一个共轭向量组，将解向量表示为该向量组的线性组合：
	\begin{equation}
	\boldsymbol{x}=\alpha_0\boldsymbol{p}_0+\alpha_1\boldsymbol{p}_1+\cdots+\alpha_{n-1}\boldsymbol{p}_{n-1}
	\end{equation}
	则有：
	\begin{equation}
	\sum_{k=0}^{n-1}\alpha_k\boldsymbol{A}\boldsymbol{p}_k
	=\boldsymbol{b}
	\end{equation}
	所以求解$\alpha_k$时，可以通过在等值左右同时左乘一个$\boldsymbol{p}_k^\top$，将其他项消除得到：
	\begin{equation}
	\alpha_k=\frac{<\boldsymbol{b,\boldsymbol{p}_k}>}{<\boldsymbol{A}\boldsymbol{p}_k,\boldsymbol{p}_k>}
	\end{equation}
	得到$\alpha_k$也即求解得到解向量。
	
	计算流程为：
	\begin{enumerate}
	\item 选定初值$\boldsymbol{x}_0$，则$\boldsymbol{r}_0=\boldsymbol{b}-\boldsymbol{Ax}_0$，令$\boldsymbol{p}_0=\boldsymbol{r}_0$；
	
	\item 计算步长：$\alpha_k=<\boldsymbol{r}_k,\boldsymbol{p}_k>/<\boldsymbol{Ap}_k,\boldsymbol{p}_k>$；
	
	\item 更新解向量：$\boldsymbol{x}_{k+1}=\boldsymbol{x}_k+\alpha \boldsymbol{p}_k$；
	
	\item 更新残差：$\boldsymbol{r}_{k+1}=\boldsymbol{b}-\boldsymbol{Ax}_{k+1}=\boldsymbol{r}_k-\alpha_k\boldsymbol{Ap}_k$；
	
	\item 计算：$\beta_k=<\boldsymbol{r}_{k+1},\boldsymbol{r}_{k+1}>/<\boldsymbol{r}_{k},\boldsymbol{r}_{k}>$；
	
	\item 更新方向：$\boldsymbol{p}_{k+1}=\boldsymbol{r}_{k+1}+\beta_k\boldsymbol{p}_k$；
	\end{enumerate}
	
	\subsection{\normf{实验结果}}
	\subsubsection{\normf{小型矩阵测试}}
	设要求解的线性方程组为：
		\begin{equation}
		\begin{pmatrix}
		3&2\\2&6
		\end{pmatrix}\boldsymbol{x}=\begin{pmatrix}
		2\\-8
		\end{pmatrix}
		\end{equation}
		迭代的初始值$\boldsymbol{x}^{(0)}$选取两种：
		\begin{equation}
		\boldsymbol{x}_0^{(0)}=\begin{pmatrix}
		-2&-2
		\end{pmatrix}^\top
		\quad
		\boldsymbol{x}_1^{(0)}=\begin{pmatrix}
			5&2
			\end{pmatrix}^\top
		\end{equation}
		
		图\ref{fig:共轭梯度下降法迭代过程图}描述了该测试案例中的迭代过程，其中左图对于第一种初值选取，右图对应第二种初值选取。可以看到相较于“最速下降法”，“共轭梯度下降法”迭代次数更少。在两种初值选取中，都只用了2次迭代，即可到达最低点：
		\begin{equation}
		\boldsymbol{x}_{gt}=\begin{pmatrix}
		2,-2
		\end{pmatrix}^\top
		\end{equation}
			\begin{figure}[h]
				\centering
				\includegraphics[width=0.48\linewidth]{../img/conj_grad_1.pdf}
				\includegraphics[width=0.48\linewidth]{../img/conj_grad_2.pdf}
				\caption{\normf 不同初值下的共轭梯度下降法迭代过程图}
				\label{fig:共轭梯度下降法迭代过程图}
			\end{figure}
	\subsubsection{\normf{大型稀疏矩阵测试}}
	通过构建形如：
		\begin{equation}
		\boldsymbol{A}=\begin{pmatrix}
		2&-1&0&&&\cdots\\
		-1&2&-1&0&&\cdots\\
		0&-1&2&-1&0&\cdots\\
		&&\cdots\\
		&&\cdots&-1&2&-1\\
		&&\cdots&&-1&2
		\end{pmatrix}
		\end{equation}
		的系数矩阵，而后随机生成$\boldsymbol{x}$向量，进而得到$\boldsymbol{b}$向量。解向量的初值设为零向量。
		
		本次一共测试了三种维度的矩阵：$10\times 10$、$100\times 100$和$1000\times 1000$的矩阵。结果如下表所示。可以看到，相较于“最速下降法”，“共轭梯度下降”的迭代次数明显减小，运行时间更短，计算的误差更小。
		\begin{table}[h]
		\normf
			\centering
			\caption{\normf 测试结果}
			\vspace{2mm}
		\begin{tabular}{c|cccc}
		\hline
		矩阵维数 & 迭代次数 & 迭代阈值  & 运行时间（秒）     & 计算误差       \\ \hline
		10   & 11   & 1e-10 & 3.66380e-05 & 1.0000e-30 \\
		100  & 101  & 1e-10 & 1.36137e-04 & 1.2680e-27 \\
		1000 & 1001 & 1e-10 & 1.12081e-01 & 6.3807e-22 \\ \hline
		\end{tabular}
		\end{table}
		
		基于上述实验，可以得到：
		\begin{enumerate}
		\item 当目标函数为二次函数时，具有最优的收敛速度，即最多迭代 n 次就可以得到精确解，其中 n 是未知数的个数。
		
		\item 不需要存储整个系数矩阵，只需要每次计算矩阵和向量的乘积，因此节省了存储空间和计算时间。
		
		\item 可以用于求解大规模的稀疏线性方程组，也可以用于求解非线性方程组和最优化问题。
		
		\item 对初始值敏感，不同的初始值可能导致不同的收敛速度和迭代次数。
		
		\item 对系数矩阵的条件数敏感，条件数越大，收敛速度越慢，甚至可能发散。
		
		\item 需要计算矩阵和向量的乘积，如果矩阵非常稠密或者结构复杂，这一步可能很耗时。
		\end{enumerate}
		
	\subsection{\normf{关键代码}}
	\begin{lstlisting}[caption=\normf{共轭梯度下降法}]
    void conjugate_gradient(const Eigen::MatrixXd &AMat, const Eigen::VectorXd &bVec, const Eigen::VectorXd &xVec0,
                            Eigen::VectorXd &xVec, double thresh) {
        xVec = xVec0;
        Eigen::VectorXd rVec = bVec - AMat * xVec;
        Eigen::VectorXd pVec = rVec;
        while (true) {
            Eigen::VectorXd ap = AMat * pVec;
            double alpha = rVec.dot(pVec) / ap.dot(pVec);
            xVec = xVec + alpha * pVec;
            if (alpha * pVec.squaredNorm() < thresh) {
                break;
            }
            double beta1 = rVec.dot(rVec);
            rVec = rVec - alpha * ap;
            double beta2 = rVec.dot(rVec) / beta1;
            pVec = rVec + beta2 * pVec;
        }
    }
	\end{lstlisting}
		
	\newpage
	\section{ACKNOWLEDGMENT}
	\begin{tcolorbox}[colback=white,colframe=white!70!black,title={\bfseries Author Information}]
	\par\noindent
		\parbox[t]{\linewidth}{
	 \noindent\parpic{\includegraphics[height=2in,width=1in,clip,keepaspectratio]{ShuolongChen_grey.jpg}}
	 \noindent{\bfseries Shuolong Chen}\emph{
	 received the B.S. degree in geodesy and geomatics engineering from Wuhan University, Wuhan China, in 2023.
	 He is currently a master candidate at the school of Geodesy and Geomatics, Wuhan University. His area of research currently focuses on integrated navigation systems and multi-sensor fusion.
	 Contact him via e-mail: shlchen@whu.edu.cn.
	 }}
	\end{tcolorbox}
		
		
\end{document}

